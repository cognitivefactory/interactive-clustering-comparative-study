{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27aaf1c9",
   "metadata": {},
   "source": [
    "# ==== INTERACTIVE CLUSTERING : EFFICIENCE STUDY ====\n",
    "> ### Stage 4 : Plot some figures according to previous stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272a43a3",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a26800",
   "metadata": {},
   "source": [
    "## READ-ME BEFORE RUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d6d2a",
   "metadata": {},
   "source": [
    "### Quick Description\n",
    "\n",
    "This notebook is **aimed at plot several figures according to previous analyses**.\n",
    "- Environments are represented by subdirectories in the `/experiments` folder. A full path to an experiment environment is `/experiments/[DATASET]/[PREPROCESSING]/[VECTORIZATION]/[SAMPLING]/[CLUSTERING]/[EXPERIMENT]`.\n",
    "- An experiment run is composed of iterations of _interative clustering_.\n",
    "- An experiment evaluation look at each _interative clustering_ iteration of the experiment.\n",
    "\n",
    "Before running, **run the notebook `3_Analyze_main_effects_and_post_hoc.ipynb` to run main effects and and post-hoc analysis on interactive clustering convergence speed over experiments.**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ca79c",
   "metadata": {},
   "source": [
    "### Description each steps\n",
    "\n",
    "1. First section is aimed at compare performance of unconstrained clustering\n",
    "2. Second section is aimed at display estimation of performance accross iterations for several combinations of algorithm, parameters, or experiments.\n",
    "3. Third section is aimed at display iteration required to obtain performance goals for several combinations of algorithm, parameters, or experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1cd89d",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c66064",
   "metadata": {},
   "source": [
    "## 1. Compute average performance of unconstrained clustering (iteration 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0ea66",
   "metadata": {},
   "source": [
    "***WARNING***: _Start by launching the experiment runs, evaluations and synthesis, and launching main effects analysis before this section !_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53691c1",
   "metadata": {},
   "source": [
    "Import Python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c516df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import listing_envs\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats as scipystats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef321a",
   "metadata": {},
   "source": [
    "Find all experiment environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of experiment environments.\n",
    "LIST_OF_EXPERIMENT_ENVIRONMENTS: List[\n",
    "    str\n",
    "] = listing_envs.get_list_of_experiment_env_paths()\n",
    "print(\n",
    "    \"There are\",\n",
    "    \"`\" + str(len(LIST_OF_EXPERIMENT_ENVIRONMENTS)) + \"`\",\n",
    "    \"experiment environments in `../experiments`\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1327d1a",
   "metadata": {},
   "source": [
    "Get clustering performances at iteration 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03697024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list of clustering performances at iteration 0.\n",
    "list_of_clustering_performances_at_iteration_0: List[float] = []\n",
    "\n",
    "# For each environment...\n",
    "for ENV_PATH in LIST_OF_EXPERIMENT_ENVIRONMENTS:\n",
    "\n",
    "    # Load dictionary of clustering performances.\n",
    "    with open(\n",
    "        ENV_PATH + \"dict_of_clustering_performances.json\", \"r\"\n",
    "    ) as file_clustering_performances:\n",
    "        list_of_clustering_performances_at_iteration_0.append(\n",
    "            json.load(file_clustering_performances)[\"0000\"][\"v_measure\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ff7f7",
   "metadata": {},
   "source": [
    "Compute statistics on clustering performances at iteration 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869df1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute min of clustering performances at iteration 0.\n",
    "perf_min: float = min(list_of_clustering_performances_at_iteration_0)\n",
    "print(\"perf_min \", \":\", perf_min)\n",
    "# Compute max of clustering performances at iteration 0.\n",
    "perf_max: float = max(list_of_clustering_performances_at_iteration_0)\n",
    "print(\"perf_max \", \":\", perf_max)\n",
    "# Compute mean of clustering performances at iteration 0.\n",
    "perf_mean: float = np.mean(list_of_clustering_performances_at_iteration_0)\n",
    "print(\"perf_mean\", \":\", perf_mean)\n",
    "# Compute standard deviation of clustering performances at iteration 0.\n",
    "perf_std: float = np.std(list_of_clustering_performances_at_iteration_0)\n",
    "print(\"perf_std \", \":\", perf_std)\n",
    "# Compute standard deviation of clustering performances at iteration 0.\n",
    "perf_sem: float = scipystats.sem(list_of_clustering_performances_at_iteration_0)\n",
    "print(\"perf_sem \", \":\", perf_sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a40f5",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd095b",
   "metadata": {},
   "source": [
    "## 2. Plots somes graphs and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9358e732",
   "metadata": {},
   "source": [
    "***WARNING***: _Start by launching the experiment runs, evaluations and synthesis, and launching main effects analysis before this section !_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371333d",
   "metadata": {},
   "source": [
    "### 2.1. Load Python dependencies and Experiements data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7cf296",
   "metadata": {},
   "source": [
    "Import Python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f876a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "import listing_envs\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from scipy import stats as scipystats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651dbdb6",
   "metadata": {},
   "source": [
    "Find all experiment environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a78c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of experiment environments.\n",
    "LIST_OF_EXPERIMENT_ENVIRONMENTS: List[\n",
    "    str\n",
    "] = listing_envs.get_list_of_experiment_env_paths()\n",
    "print(\n",
    "    \"There are\",\n",
    "    \"`\" + str(len(LIST_OF_EXPERIMENT_ENVIRONMENTS)) + \"`\",\n",
    "    \"experiment environments in `../experiments`\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da13d0",
   "metadata": {},
   "source": [
    "### 2.2. Display iteration needed to annotated the groundtruth (_efficiency_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb95d8",
   "metadata": {},
   "source": [
    "Define the list of iteration to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare histograms.\n",
    "list_of_090vmeasure_iterations = []\n",
    "list_of_100vmeasure_iterations = []\n",
    "list_of_convergence_iterations = []\n",
    "\n",
    "# For each environment...\n",
    "for env_1 in LIST_OF_EXPERIMENT_ENVIRONMENTS:\n",
    "\n",
    "    # Load annotations for the current experiment.\n",
    "    with open(\n",
    "        env_1 + \"dict_of_constraints_annotations.json\", \"r\"\n",
    "    ) as annotation_file:\n",
    "        dict_of_constraints_annotations: Dict[\n",
    "            str, List[Tuple[str, str, Optional[str]]]\n",
    "        ] = json.load(annotation_file)\n",
    "            \n",
    "    # Load clustering performance for the current experiment.\n",
    "    with open(\n",
    "        env_1 + \"dict_of_clustering_performances.json\", \"r\"\n",
    "    ) as evaluations_file:\n",
    "        dict_of_clustering_evaluations: Dict[\n",
    "            str, Dict[str, float]\n",
    "        ] = json.load(evaluations_file)\n",
    "\n",
    "    # Update histogram for convergence.\n",
    "    current_max_iteration: str = max(dict_of_constraints_annotations.keys())\n",
    "    list_of_convergence_iterations.append(int(current_max_iteration))\n",
    "    \n",
    "    # Update histogram for vmeasure=100.\n",
    "    if dict_of_clustering_evaluations[current_max_iteration][\"v_measure\"] < 1.00:\n",
    "        list_of_100vmeasure_iterations.append(-1)\n",
    "    else:\n",
    "        for iteration in sorted(dict_of_clustering_evaluations.keys(), reverse=True):\n",
    "            if dict_of_clustering_evaluations[iteration][\"v_measure\"] < 1.00:\n",
    "                break\n",
    "            continue\n",
    "        list_of_100vmeasure_iterations.append(int(iteration))\n",
    "\n",
    "    # Update histogram for vmeasure=090.\n",
    "    if dict_of_clustering_evaluations[current_max_iteration][\"v_measure\"] < 0.90:\n",
    "        list_of_090vmeasure_iterations.append(-1)\n",
    "    else:\n",
    "        for iteration in sorted(dict_of_clustering_evaluations.keys(), reverse=True):\n",
    "            if dict_of_clustering_evaluations[iteration][\"v_measure\"] < 0.90:\n",
    "                break\n",
    "            continue\n",
    "        list_of_090vmeasure_iterations.append(int(iteration))\n",
    "            \n",
    "# Get maximum iteration.\n",
    "MAX_ITER: str = str(max(list_of_convergence_iterations)).zfill(4)\n",
    "# If set, force maximum iteration.\n",
    "####if forced_max_iter is not None:\n",
    "####    MAX_ITER = min(MAX_ITER, forced_max_iter)\n",
    "print(\"MAX_ITER:\", MAX_ITER)\n",
    "\n",
    "# Set list of iterations to analyze.\n",
    "LIST_OF_ITERATIONS: List[str] = [str(i).zfill(4) for i in range(int(MAX_ITER))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c63d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_hist0: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_hist0 = fig_hist0.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_hist0.set_xlim(xmin=-1, xmax=int(max(LIST_OF_ITERATIONS))+1)\n",
    "\n",
    "# Plot histogram of iteration for vmeausre 90%.\n",
    "axis_hist0.hist(\n",
    "    list_of_090vmeasure_iterations,\n",
    "    bins=2*int(math.sqrt(len(list_of_090vmeasure_iterations))),  # int(len(LIST_OF_ITERATIONS)/2),\n",
    "    label=\"Tentatives ayant atteint une annotation\\npartielle (90% de v-measure)\",\n",
    "    color=\"green\",\n",
    ")\n",
    "print(\"bins:\", 2*int(math.sqrt(len(list_of_090vmeasure_iterations))))\n",
    "\n",
    "# Set axis name.\n",
    "axis_hist0.set_xlabel(\"itération [#]\", fontsize=18,)\n",
    "axis_hist0.set_ylabel(\"tentative [#]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_hist0.legend(loc=\"upper right\", fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_hist0.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_hist0.savefig(\n",
    "    \"../results/etude-efficience-histogramme-annotation-partielle.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_hist1: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_hist1 = fig_hist1.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_hist1.set_xlim(xmin=-1, xmax=int(max(LIST_OF_ITERATIONS))+1)\n",
    "\n",
    "# Plot histogram of iteration for vmeausre 100%.\n",
    "axis_hist1.hist(\n",
    "    list_of_100vmeasure_iterations,\n",
    "    bins=2*int(math.sqrt(len(list_of_100vmeasure_iterations))),  # int(len(LIST_OF_ITERATIONS)/2),\n",
    "    label=\"Tentatives ayant atteint une annotation\\nsuffisante (100% de v-measure)\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "print(\"bins:\", 2*int(math.sqrt(len(list_of_100vmeasure_iterations))))\n",
    "\n",
    "# Set axis name.\n",
    "axis_hist1.set_xlabel(\"itération [#]\", fontsize=18,)\n",
    "axis_hist1.set_ylabel(\"tentative [#]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_hist1.legend(loc=\"upper right\", fontsize=15)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_hist1.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_hist1.savefig(\n",
    "    \"../results/etude-efficience-histogramme-annotation-suffisante.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c3f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_hist2: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_hist2 = fig_hist2.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_hist2.set_xlim(xmin=-1, xmax=int(max(LIST_OF_ITERATIONS))+1)\n",
    "\n",
    "# Plot histogram of iteration for convergence.\n",
    "axis_hist2.hist(\n",
    "    list_of_convergence_iterations,\n",
    "    bins=2*int(math.sqrt(len(list_of_convergence_iterations))),  # int(len(LIST_OF_ITERATIONS)/2),\n",
    "    label=\"Tentatives ayant atteint une annotation\\nexhaustive (toutes les contraintes)\",\n",
    "    color=\"red\",\n",
    ")\n",
    "print(\"bins:\", 2*int(math.sqrt(len(list_of_convergence_iterations))))\n",
    "\n",
    "# Set axis name.\n",
    "axis_hist2.set_xlabel(\"itération [#]\", fontsize=18,)\n",
    "axis_hist2.set_ylabel(\"tentative [#]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_hist2.legend(loc=\"upper right\", fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_hist2.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_hist2.savefig(\n",
    "    \"../results/etude-efficience-histogramme-annotation-exhaustive.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd531e03",
   "metadata": {},
   "source": [
    "### 2.3. Display mean of performance per iterations (_efficiency_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec849b",
   "metadata": {},
   "source": [
    "Define main functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    ") -> Tuple[Dict[str, float], Dict[str, float], Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute evolution of performance accross iterations.\n",
    "    Return Mean, Standard deviation and Standard error of the mean evolutions\n",
    "    \n",
    "    Args:\n",
    "        local_LIST_OF_ITERATIONS (List[str]): The list of iterations to consider.\n",
    "        local_LIST_OF_EXPERIMENT_ENVIRONMENTS (List[str]): The list of experiments to consider.\n",
    "    Returns:\n",
    "        Tuple[Dict[str, float], Dict[str, float], Dict[str, float]]: Evolutions of Mean, Standard deviation and Standard error of the mean accross iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize storage of experiment performances for all iterations.\n",
    "    dict_of_global_performances_evolution_per_iteration: Dict[str, List[float]] = {\n",
    "        iter_perf: [] for iter_perf in local_LIST_OF_ITERATIONS\n",
    "    }\n",
    "    # Initialize storage of performance mean for all iterations.\n",
    "    dict_of_global_performances_evolution_per_iteration_MEAN: Dict[str, float] = {\n",
    "        iter_mean: 0 for iter_mean in local_LIST_OF_ITERATIONS\n",
    "    }\n",
    "    # Initialize storage of performance standard deviation for all iterations.\n",
    "    dict_of_global_performances_evolution_per_iteration_STDEV: Dict[str, float] = {\n",
    "        iter_stdev: 0 for iter_stdev in local_LIST_OF_ITERATIONS\n",
    "    }\n",
    "    # Initialize storage of performance standard error of the mean for all iterations.\n",
    "    dict_of_global_performances_evolution_per_iteration_SEM: Dict[str, float] = {\n",
    "        iter_sem: 0 for iter_sem in local_LIST_OF_ITERATIONS\n",
    "    }\n",
    "\n",
    "    # For each experiment...\n",
    "    for env_a in local_LIST_OF_EXPERIMENT_ENVIRONMENTS:\n",
    "\n",
    "        # Load clustering evaluations.\n",
    "        with open(\n",
    "            env_a + \"dict_of_clustering_performances.json\", \"r\"\n",
    "        ) as evaluation_file:\n",
    "            dict_of_clustering_performances: Dict[\n",
    "                str, Dict[str, float]\n",
    "            ] = json.load(evaluation_file)\n",
    "\n",
    "        # For each requested iteration...\n",
    "        for iter_a in local_LIST_OF_ITERATIONS:\n",
    "\n",
    "            # Append the clustering performancre for the current experiment and for this iteration.\n",
    "            if iter_a in dict_of_clustering_performances.keys():\n",
    "                dict_of_global_performances_evolution_per_iteration[iter_a].append(\n",
    "                    dict_of_clustering_performances[iter_a][\"v_measure\"]\n",
    "                )\n",
    "            # If iteration isn't reached by this experiment, duplicate the last known results.\n",
    "            # Most of the time: the experiment has reached annotation completeness and there is no more iteration because clustering is \"perfect\" (v-measure==1.0).\n",
    "            else:\n",
    "                dict_of_global_performances_evolution_per_iteration[iter_a].append(1.0)\n",
    "\n",
    "    # Compute mean and sem of performance for each iteration.\n",
    "    for iter_b in local_LIST_OF_ITERATIONS:\n",
    "\n",
    "        # Compute mean of performance for this iteration.\n",
    "        dict_of_global_performances_evolution_per_iteration_MEAN[iter_b] = np.mean(dict_of_global_performances_evolution_per_iteration[iter_b])\n",
    "        \n",
    "        # Compute stdev of performance for this iteration.\n",
    "        dict_of_global_performances_evolution_per_iteration_STDEV[iter_b] = np.std(dict_of_global_performances_evolution_per_iteration[iter_b])\n",
    "\n",
    "        # Compute sem of performance for this iteration.\n",
    "        dict_of_global_performances_evolution_per_iteration_SEM[iter_b] = scipystats.sem(dict_of_global_performances_evolution_per_iteration[iter_b])\n",
    "        \n",
    "    # Return\n",
    "    return (\n",
    "        dict_of_global_performances_evolution_per_iteration_MEAN,\n",
    "        dict_of_global_performances_evolution_per_iteration_STDEV,\n",
    "        dict_of_global_performances_evolution_per_iteration_SEM\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis,\n",
    "    list_of_x: List[str],\n",
    "    dict_of_y: Dict[str, float],\n",
    "    dict_of_y_err: Optional[Dict[str, float]] = None,\n",
    "    label: str = \"\",\n",
    "    marker: str = \"\",\n",
    "    markersize: int = 5,\n",
    "    color: str = \"black\",\n",
    "    linewidth: int = 2,\n",
    "    linestyle: str = \"-\",\n",
    "    alpha: float = 0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Add a plot to an axis of a graph.\n",
    "    \n",
    "    Args:\n",
    "        axis (): TODO.\n",
    "        list_of_x (List[str]): TODO.\n",
    "        dict_of_y (Dict[str, float]): TODO.\n",
    "        dict_of_y_err (Optional[Dict[str, float]]): TODO. Defaults to `None`.\n",
    "        label (str): TODO. Defaults to `\"\"`.\n",
    "        marker (str): TODO. Defaults to `\"\"`.\n",
    "        markersize (int): TODO. Defaults to `5`.\n",
    "        color (str): TODO. Defaults to `\"black\"`.\n",
    "        linewidth (int): TODO. Defaults to `2`.\n",
    "        linestyle (str): TODO. Defaults to `\"-\"`.\n",
    "        alpha (float): TODO. Defaults to `0.2`.\n",
    "    \"\"\"\n",
    "    # Add curve.\n",
    "    axis.plot(\n",
    "        [float(x) for x in list_of_x],  # x\n",
    "        [dict_of_y[x] for x in list_of_x],  # y\n",
    "        label=label,\n",
    "        marker=marker,\n",
    "        markerfacecolor=color,\n",
    "        markersize=markersize,\n",
    "        color=color,\n",
    "        linewidth=linewidth,\n",
    "        linestyle=linestyle,\n",
    "    )\n",
    "    # Add curve error bars.\n",
    "    if dict_of_y_err is not None:\n",
    "        axis.fill_between(\n",
    "            [float(x) for x in list_of_x],  # x\n",
    "            y1=[(dict_of_y[x] - dict_of_y_err[x]) for x in list_of_x],  # y1\n",
    "            y2=[(dict_of_y[x] + dict_of_y_err[x]) for x in list_of_x],  # y2\n",
    "            color=color,\n",
    "            alpha=alpha,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91850bd9",
   "metadata": {},
   "source": [
    "Evolution of performance per iteration for MEAN EXPERIMENT + FASTEST + LOWEST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_average1: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_average1 = fig_plot_average1.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_average1.set_xlim(xmin=-2, xmax=int(max(LIST_OF_ITERATIONS))+2)\n",
    "axis_plot_average1.set_ylim(ymin=-0.01, ymax=1.01)\n",
    "\n",
    "# Load fastest (too reach vmeasure=100%) clustering evaluations.\n",
    "env_fastest_100 = \"../experiments/bank_cards_v1/simple_prep/tfidf/closest-50/hier_comp-10c/0001/\"\n",
    "with open(\n",
    "    env_fastest_100 + \"dict_of_clustering_performances.json\", \"r\"\n",
    ") as evaluation_file:\n",
    "    dict_of_clustering_performances_for_fastest_100: Dict[\n",
    "        str, Dict[str, float]\n",
    "    ] = json.load(evaluation_file)\n",
    "# Plot fastest average clustering performance evolution.\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_average1,\n",
    "    list_of_x=[\n",
    "        iter_plot for iter_plot in LIST_OF_ITERATIONS\n",
    "        if iter_plot in dict_of_clustering_performances_for_fastest_100.keys()\n",
    "    ],\n",
    "    dict_of_y={\n",
    "        iter_plot:dict_of_clustering_performances_for_fastest_100[iter_plot][\"v_measure\"]\n",
    "        for iter_plot in LIST_OF_ITERATIONS\n",
    "        if iter_plot in dict_of_clustering_performances_for_fastest_100.keys()\n",
    "    },\n",
    "    dict_of_y_err=None,\n",
    "    label=\"Tentative la plus rapide\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Load slowest (too reach vmeasure=100%) clustering evaluations.\n",
    "env_slowest_100 = \"../experiments/bank_cards_v1/no_prep/tfidf/farthest-50/spectral_SPEC-10c/0001/\"\n",
    "with open(\n",
    "    env_slowest_100 + \"dict_of_clustering_performances.json\", \"r\"\n",
    ") as evaluation_file:\n",
    "    dict_of_clustering_performances_for_slowest_100: Dict[\n",
    "        str, Dict[str, float]\n",
    "    ] = json.load(evaluation_file)\n",
    "# Plot lowest average clustering performance evolution.\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_average1,\n",
    "    list_of_x=[\n",
    "        iter_plot for iter_plot in LIST_OF_ITERATIONS\n",
    "        if iter_plot in dict_of_clustering_performances_for_slowest_100.keys()\n",
    "    ],\n",
    "    dict_of_y={\n",
    "        iter_plot:dict_of_clustering_performances_for_slowest_100[iter_plot][\"v_measure\"]\n",
    "        for iter_plot in LIST_OF_ITERATIONS\n",
    "        if iter_plot in dict_of_clustering_performances_for_slowest_100.keys()\n",
    "    },  # y\n",
    "    dict_of_y_err=None,\n",
    "    label=\"Tentative la plus lente\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Mean of performance.\n",
    "MEAN_convergence_ALL, STDEV_convergence_ALL, SEM_convergence_ALL = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    ")\n",
    "# Plot average clustering performance evolution.\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_average1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_convergence_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_average1.set_xlabel(\"itération [#]\", fontsize=18,)\n",
    "axis_plot_average1.set_ylabel(\"v-measure [%]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_average1.legend(fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_average1.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_average1.savefig(\n",
    "    \"../results/etude-efficacite-evolution-moyenne-0par-iteration.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_of_iterations = []\n",
    "for iteration in [\"0000\", \"0025\", \"0050\", \"0075\", \"0100\", \"0125\", \"0150\", \"0200\", \"0250\", \"0300\"]:\n",
    "    min_vmeasure: float = 1.0\n",
    "    max_vmeasure: float = 0.0\n",
    "    \n",
    "    for env in LIST_OF_EXPERIMENT_ENVIRONMENTS:\n",
    "\n",
    "        # Load clustering evaluations.\n",
    "        with open(\n",
    "            env + \"dict_of_clustering_performances.json\", \"r\"\n",
    "        ) as evaluation_file:\n",
    "            dict_of_clustering_performances: Dict[\n",
    "                str, Dict[str, float]\n",
    "            ] = json.load(evaluation_file)\n",
    "        vmeasure: float = (\n",
    "            dict_of_clustering_performances[iteration][\"v_measure\"]\n",
    "            if iteration in dict_of_clustering_performances.keys()\n",
    "            else 1.0\n",
    "        )\n",
    "        min_vmeasure = min(min_vmeasure, vmeasure)\n",
    "        max_vmeasure = max(max_vmeasure, vmeasure)\n",
    "    \n",
    "    description_of_iterations.append([\n",
    "        iteration,\n",
    "        int(iteration)*50,\n",
    "        \"{0:.2f}\".format(MEAN_convergence_ALL[iteration]*100),\n",
    "        \"{0:.2f}\".format(STDEV_convergence_ALL[iteration]*100),\n",
    "        \"{0:.2f}\".format(SEM_convergence_ALL[iteration]*100),\n",
    "        \"{0:.2f}\".format(min_vmeasure*100),\n",
    "        \"{0:.2f}\".format(max_vmeasure*100),\n",
    "    ])\n",
    "pd.DataFrame(\n",
    "    data=description_of_iterations,\n",
    "    columns=[\"iteration [#]\", \"constraints [#]\", \"mean [%]\", \"stdev [%]\", \"sem [%]\", \"min [%]\", \"max [%]\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fa887",
   "metadata": {},
   "source": [
    "Evolution of performance per iteration of MEAN + PREPROCESSING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53efe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_prep1: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_prep1 = fig_plot_prep1.gca()\n",
    "\n",
    "# Set range of axis\n",
    "axis_plot_prep1.set_xlim(xmin=-1, xmax=201)\n",
    "axis_plot_prep1.set_ylim(ymin=-0.01, ymax=1.01)\n",
    "\n",
    "# Plot average clustering performance evolution for no-prep.\n",
    "MEAN_convergence_no_prep, STDEV_convergence_no_prep, SEM_convergence_no_prep = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"no_prep\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_prep1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_no_prep,\n",
    "    #dict_of_y_err=STDEV_convergence_no_prep,\n",
    "    dict_of_y_err=SEM_convergence_no_prep,\n",
    "    label=\"Moyenne des tentatives avec le prétraitement 'prep.no'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for simple-prep.\n",
    "MEAN_convergence_simple_prep, STDEV_convergence_simple_prep, SEM_convergence_simple_prep = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"simple_prep\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_prep1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_simple_prep,\n",
    "    #dict_of_y_err=STDEV_convergence_simple_prep,\n",
    "    dict_of_y_err=SEM_convergence_simple_prep,\n",
    "    label=\"Moyenne des tentatives avec le prétraitement 'prep.simple'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for lemma-prep.\n",
    "MEAN_convergence_lemma_prep, STDEV_convergence_lemma_prep, SEM_convergence_lemma_prep = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"lemma_prep\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_prep1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_lemma_prep,\n",
    "    #dict_of_y_err=STDEV_convergence_lemma_prep,\n",
    "    dict_of_y_err=SEM_convergence_lemma_prep,\n",
    "    label=\"Moyenne des tentatives avec le prétraitement 'prep.lemma'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for filter-prep.\n",
    "MEAN_convergence_filter_prep, STDEV_convergence_filter_prep, SEM_convergence_filter_prep = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"filter_prep\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_prep1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_filter_prep,\n",
    "    #dict_of_y_err=STDEV_convergence_filter_prep,\n",
    "    dict_of_y_err=SEM_convergence_filter_prep,\n",
    "    label=\"Moyenne des tentatives avec le prétraitement 'prep.filter'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"orange\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "MEAN_convergence_ALL, STDEV_convergence_ALL, SEM_convergence_ALL = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_prep1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_convergence_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_prep1.set_xlabel(\"itération [#]\", fontsize=18,)\n",
    "axis_plot_prep1.set_ylabel(\"v-measure [%]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_prep1.legend(fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_prep1.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_prep1.savefig(\n",
    "    \"../results/etude-efficacite-evolution-moyenne-1preprocessing-par-iteration.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d45316",
   "metadata": {},
   "source": [
    "Evolution of performance per iteration of MEAN + VECTORIZATION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_vect1: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_vect1 = fig_plot_vect1.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_vect1.set_xlim(xmin=-1, xmax=201)\n",
    "axis_plot_vect1.set_ylim(ymin=-0.01, ymax=1.01)\n",
    "\n",
    "# Plot average clustering performance evolution for tfidf.\n",
    "MEAN_convergence_tfidf, STDEV_convergence_tfidf, SEM_convergence_tfidf = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"tfidf\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_vect1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_tfidf,\n",
    "    #dict_of_y_err=STDEV_convergence_tfidf,\n",
    "    dict_of_y_err=SEM_convergence_tfidf,\n",
    "    label=\"Moyenne des tentatives avec la vectorisation 'vect.tfidf'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for fr-core-news-md.\n",
    "MEAN_convergence_fr_core_news_md, STDEV_convergence_fr_core_news_md, SEM_convergence_fr_core_news_md = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"fr_core_news_md\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_vect1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_fr_core_news_md,\n",
    "    #dict_of_y_err=STDEV_convergence_fr_core_news_md,\n",
    "    dict_of_y_err=SEM_convergence_fr_core_news_md,\n",
    "    label=\"Moyenne des tentatives avec la vectorisation 'vect.frcorenewsmd'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "MEAN_convergence_ALL, STDEV_convergence_ALL, SEM_convergence_ALL = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_vect1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_convergence_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_vect1.set_xlabel(\"itération [#]\", fontsize=18,)\n",
    "axis_plot_vect1.set_ylabel(\"v-measure [%]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_vect1.legend(fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_vect1.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_vect1.savefig(\n",
    "    \"../results/etude-efficacite-evolution-moyenne-2vectorization-par-iteration.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e850d",
   "metadata": {},
   "source": [
    "Evolution of performance per iteration of MEAN + CLUSTERING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5587681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_clust1: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_clust1 = fig_plot_clust1.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_clust1.set_xlim(xmin=-1, xmax=201)\n",
    "axis_plot_clust1.set_ylim(ymin=-0.01, ymax=1.01)\n",
    "\n",
    "# Plot average clustering performance evolution for kmeans_COP.\n",
    "MEAN_convergence_kmeans_COP, STDEV_convergence_kmeans_COP, SEM_convergence_kmeans_COP = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"kmeans_COP\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_clust1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_kmeans_COP,\n",
    "    #dict_of_y_err=STDEV_convergence_kmeans_COP,\n",
    "    dict_of_y_err=SEM_convergence_kmeans_COP,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.kmeans.cop'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for hier_sing.\n",
    "MEAN_convergence_hier_sing, STDEV_convergence_hier_sing, SEM_convergence_hier_sing = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"hier_sing\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_clust1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_hier_sing,\n",
    "    #dict_of_y_err=STDEV_convergence_hier_sing,\n",
    "    dict_of_y_err=SEM_convergence_hier_sing,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.hier.sing'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for hier_comp.\n",
    "MEAN_convergence_hier_comp, STDEV_convergence_hier_comp, SEM_convergence_hier_comp = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"hier_comp\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_clust1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_hier_comp,\n",
    "    #dict_of_y_err=STDEV_convergence_hier_comp,\n",
    "    dict_of_y_err=SEM_convergence_hier_comp,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.hier.comp'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "    \n",
    "# Plot average clustering performance evolution for hier_avg.\n",
    "MEAN_convergence_hier_avg, STDEV_convergence_hier_avg, SEM_convergence_hier_avg = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"hier_avg\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_clust1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_hier_avg,\n",
    "    #dict_of_y_err=STDEV_convergence_hier_avg,\n",
    "    dict_of_y_err=SEM_convergence_hier_avg,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.hier.avg'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"orange\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for hier_ward.\n",
    "MEAN_convergence_hier_ward, STDEV_convergence_hier_ward, SEM_convergence_hier_ward = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"hier_ward\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_clust1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_hier_ward,\n",
    "    #dict_of_y_err=STDEV_convergence_hier_ward,\n",
    "    dict_of_y_err=SEM_convergence_hier_ward,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.hier.ward'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"violet\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "    \n",
    "# Plot average clustering performance evolution for spectral_SPEC.\n",
    "MEAN_convergence_spectral_SPEC, STDEV_convergence_spectral_SPEC, SEM_convergence_spectral_SPEC = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"spectral_SPEC\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_clust1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_spectral_SPEC,\n",
    "    #dict_of_y_err=STDEV_convergence_spectral_SPEC,\n",
    "    dict_of_y_err=SEM_convergence_spectral_SPEC,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.spec'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"cyan\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "MEAN_convergence_ALL, STDEV_convergence_ALL, SEM_convergence_ALL = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_clust1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_convergence_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_clust1.set_xlabel(\"itération [#]\", fontsize=18,)\n",
    "axis_plot_clust1.set_ylabel(\"v-measure [%]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_clust1.legend(fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_clust1.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_clust1.savefig(\n",
    "    \"../results/etude-efficacite-evolution-moyenne-3clustering-par-iteration.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ada118",
   "metadata": {},
   "source": [
    "Evolution of performance per iteration of MEAN + SAMPLING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd339ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_samp1: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_samp1 = fig_plot_samp1.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_samp1.set_xlim(xmin=-1, xmax=201)\n",
    "axis_plot_samp1.set_ylim(ymin=-0.01, ymax=1.01)\n",
    "\n",
    "# Plot average clustering performance evolution for random.\n",
    "MEAN_convergence_random, STDEV_convergence_random, SEM_convergence_random = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"random\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_samp1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_random,\n",
    "    #dict_of_y_err=STDEV_convergence_random,\n",
    "    dict_of_y_err=SEM_convergence_random,\n",
    "    label=\"Moyenne des tentatives avec l'échantillonnage 'samp.random.full'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for random-in-same.\n",
    "MEAN_convergence_in_same, STDEV_convergence_in_same, SEM_convergence_in_same = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"in_same\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_samp1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_in_same,\n",
    "    #dict_of_y_err=STDEV_convergence_in_same,\n",
    "    dict_of_y_err=SEM_convergence_in_same,\n",
    "    label=\"Moyenne des tentatives avec l'échantillonnage 'samp.random.same'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for farthest.\n",
    "MEAN_convergence_farthest, STDEV_convergence_farthest, SEM_convergence_farthest = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"farthest\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_samp1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_farthest,\n",
    "    #dict_of_y_err=STDEV_convergence_farthest,\n",
    "    dict_of_y_err=SEM_convergence_farthest,\n",
    "    label=\"Moyenne des tentatives avec l'échantillonnage 'samp.farthest.same'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "    \n",
    "# Plot average clustering performance evolution for closest.\n",
    "MEAN_convergence_closest, STDEV_convergence_closest, SEM_convergence_closest = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"closest\" in env\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_samp1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_closest,\n",
    "    #dict_of_y_err=STDEV_convergence_closest,\n",
    "    dict_of_y_err=SEM_convergence_closest,\n",
    "    label=\"Moyenne des tentatives avec l'échantillonnage 'samp.closest.diff'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"orange\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "MEAN_convergence_ALL, STDEV_convergence_ALL, SEM_convergence_ALL = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_samp1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_convergence_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_samp1.set_xlabel(\"itération [#]\", fontsize=18,)\n",
    "axis_plot_samp1.set_ylabel(\"v-measure [%]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_samp1.legend(fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_samp1.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_samp1.savefig(\n",
    "    \"../results/etude-efficacite-evolution-moyenne-4sampling-par-iteration.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203fc81c",
   "metadata": {},
   "source": [
    "Evolution of performance per iteration of MEAN + BEST SETTINGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd928b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_best_anova1: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_best_anova1 = fig_plot_best_anova1.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_best_anova1.set_xlim(xmin=-0.5, xmax=51)\n",
    "axis_plot_best_anova1.set_ylim(ymin=-0.01, ymax=1.01)\n",
    "\n",
    "# Plot average clustering performance evolution to reach 90% of vmeasure.\n",
    "MEAN_convergence_BEST_ANOVA_90, STDEV_convergence_BEST_ANOVA_90, SEM_convergence_BEST_ANOVA_90 = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if (\"simple_prep\" in env)\n",
    "        and (\"tfidf\" in env)\n",
    "        and (\"hier_avg\" in env)\n",
    "        and (\"closest\" in env)\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_best_anova1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_BEST_ANOVA_90,\n",
    "    #dict_of_y_err=STDEV_convergence_BEST_ANOVA_90,\n",
    "    dict_of_y_err=SEM_convergence_BEST_ANOVA_90,\n",
    "    label=\"Moyenne des tentatives ayant le meilleur paramètrage moyen\\npour atteindre une annotation partielle (90% de v-measure).\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "    \n",
    "# Plot average clustering performance evolution to reach 100% of vmeasure.\n",
    "MEAN_convergence_BEST_ANOVA_100, STDEV_convergence_BEST_ANOVA_100, SEM_convergence_BEST_ANOVA_100 = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if (\"lemma_prep\" in env)\n",
    "        and (\"tfidf\" in env)\n",
    "        and (\"kmeans_COP\" in env)\n",
    "        and (\"closest\" in env)\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_best_anova1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_BEST_ANOVA_100,\n",
    "    #dict_of_y_err=STDEV_convergence_BEST_ANOVA_100,\n",
    "    dict_of_y_err=SEM_convergence_BEST_ANOVA_100,\n",
    "    label=\"Moyenne des tentatives ayant le meilleur paramètrage moyen\\npour atteindre une annotation suffisante (100% de v-measure).\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution to reach constraints completude.\n",
    "MEAN_convergence_BEST_ANOVA_MAX, STDEV_convergence_BEST_ANOVA_MAX, SEM_convergence_BEST_ANOVA_MAX = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if (\"lemma_prep\" in env)\n",
    "        and (\"tfidf\" in env)\n",
    "        and (\"kmeans_COP\" in env)\n",
    "        and (\"in_same\" in env)\n",
    "    ],\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_best_anova1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_BEST_ANOVA_MAX,\n",
    "    #dict_of_y_err=STDEV_convergence_BEST_ANOVA_MAX,\n",
    "    dict_of_y_err=SEM_convergence_BEST_ANOVA_MAX,\n",
    "    label=\"Moyenne des tentatives ayant le meilleur paramètrage moyen\\npour atteindre une annotation exhaustive (toutes les contraintes).\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "MEAN_convergence_ALL, STDEV_convergence_ALL, SEM_convergence_ALL = get_MEAN_STDEV_SEM_of_performance_evolution_per_iteration(\n",
    "    local_LIST_OF_ITERATIONS=LIST_OF_ITERATIONS,\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    ")\n",
    "add_plot_of_performance_evolution_per_iteration_to_graph(\n",
    "    axis=axis_plot_best_anova1,\n",
    "    list_of_x=LIST_OF_ITERATIONS,\n",
    "    dict_of_y=MEAN_convergence_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_convergence_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_best_anova1.set_xlabel(\"itération [#]\", fontsize=18,)\n",
    "axis_plot_best_anova1.set_ylabel(\"v-measure [%]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_best_anova1.legend(fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_best_anova1.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_best_anova1.savefig(\n",
    "    \"../results/etude-efficacite-evolution-moyenne-5best-par-iteration.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4970046e",
   "metadata": {},
   "source": [
    "### 2.4. Display mean of iterations per performances goal (_effectiveness_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd41cd",
   "metadata": {},
   "source": [
    "Define main functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS: List[str],\n",
    "    local_LIST_OF_GOALS: List[float] = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 0.99, 1.00],\n",
    ") -> Tuple[Dict[str, float], Dict[str, float], Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Compute iteration needed according to a performance goal.\n",
    "    Return Mean, Standard deviation and Standard error of the mean evolutions.\n",
    "    \n",
    "    Args:\n",
    "        - local_LIST_OF_EXPERIMENT_ENVIRONMENTS (List[str]): The list of experiments to consider.\n",
    "        - local_LIST_OF_GOALS (List[float]): The list of performance goals to consider.\n",
    "    Returns:\n",
    "        Tuple[Dict[str, float], Dict[str, float], Dict[str, float]]: Evolutions of Mean, Standard deviation and Standard error of the mean accross performance goal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize storage of iteration needed for all goal.\n",
    "    dict_of_global_iteration_needed_per_performance_goal: Dict[str, List[float]] = {\n",
    "        goal_iter: [] for goal_iter in local_LIST_OF_GOALS\n",
    "    }\n",
    "    # Initialize storage of iteration needed mean for all goal.\n",
    "    dict_of_global_iteration_needed_per_performance_goal_MEAN: Dict[str, float] = {\n",
    "        goal_mean: [] for goal_mean in local_LIST_OF_GOALS\n",
    "    }\n",
    "    # Initialize storage of iteration needed standard deviation for all goal.\n",
    "    dict_of_global_iteration_needed_per_performance_goal_STDEV: Dict[str, float] = {\n",
    "        goal_stdev: [] for goal_stdev in local_LIST_OF_GOALS\n",
    "    }\n",
    "    # Initialize storage of iteration needed standard error of the mean for all goal.\n",
    "    dict_of_global_iteration_needed_per_performance_goal_SEM: Dict[str, float] = {\n",
    "        goal_sem: [] for goal_sem in local_LIST_OF_GOALS\n",
    "    }\n",
    "\n",
    "    # For each experiment...\n",
    "    for env_a in local_LIST_OF_EXPERIMENT_ENVIRONMENTS:\n",
    "\n",
    "        # Load iteration to highlight.\n",
    "        with open(\n",
    "            env_a + \"dict_of_iterations_to_highlight.json\", \"r\"\n",
    "        ) as evaluation_file:\n",
    "            dict_of_iterations_to_highlight: Dict[\n",
    "                str, Dict[str, Any]\n",
    "            ] = json.load(evaluation_file)\n",
    "\n",
    "        # For each requested iteration...\n",
    "        for highlight in dict_of_iterations_to_highlight.values():\n",
    "\n",
    "            # Append the clustering iteration needed for the current experiment and for this performance goal.\n",
    "            if highlight[\"goal\"] in dict_of_global_iteration_needed_per_performance_goal.keys():\n",
    "                dict_of_global_iteration_needed_per_performance_goal[highlight[\"goal\"]].append(\n",
    "                    int(highlight[\"iteration\"])\n",
    "                )\n",
    "\n",
    "    # Compute mean and sem of iteration needed for each performance goal.\n",
    "    for goal in local_LIST_OF_GOALS:\n",
    "\n",
    "        # Compute mean of performance for this performance goal.\n",
    "        dict_of_global_iteration_needed_per_performance_goal_MEAN[goal] = np.mean(\n",
    "            dict_of_global_iteration_needed_per_performance_goal[goal]\n",
    "        )\n",
    "        # Compute stdev of performance for this performance goal.\n",
    "        dict_of_global_iteration_needed_per_performance_goal_STDEV[goal] = np.std(\n",
    "            dict_of_global_iteration_needed_per_performance_goal[goal]\n",
    "        )\n",
    "        # Compute sem of performance for this performance goal.\n",
    "        dict_of_global_iteration_needed_per_performance_goal_SEM[goal] = scipystats.sem(\n",
    "            dict_of_global_iteration_needed_per_performance_goal[goal]\n",
    "        )\n",
    "        \n",
    "    # Return\n",
    "    return (\n",
    "        dict_of_global_iteration_needed_per_performance_goal_MEAN,\n",
    "        dict_of_global_iteration_needed_per_performance_goal_STDEV,\n",
    "        dict_of_global_iteration_needed_per_performance_goal_SEM\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2dc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis,\n",
    "    list_of_x,\n",
    "    dict_of_y,\n",
    "    dict_of_y_err=None,\n",
    "    label=\"\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Add a plot to an axis of a graph.\n",
    "    \n",
    "    Args:\n",
    "        - axis\n",
    "        - list_of_x\n",
    "        - dict_of_y\n",
    "        - dict_of_y_err\n",
    "        - label\n",
    "        - marker\n",
    "        - markersize\n",
    "        - color\n",
    "        - linewidth\n",
    "        - linestyle\n",
    "        - alpha\n",
    "    \"\"\"\n",
    "    axis.plot(\n",
    "        [float(x) for x in list_of_x],  # x\n",
    "        [dict_of_y[x] for x in list_of_x],  # y\n",
    "        label=label,\n",
    "        marker=marker,\n",
    "        markerfacecolor=color,\n",
    "        markersize=markersize,\n",
    "        color=color,\n",
    "        linewidth=linewidth,\n",
    "        linestyle=linestyle,\n",
    "    )\n",
    "    if dict_of_y_err is not None:\n",
    "        axis.fill_between(\n",
    "            [float(x) for x in list_of_x],  # x\n",
    "            y1=[(dict_of_y[x] - dict_of_y_err[x]) for x in list_of_x],  # y1\n",
    "            y2=[(dict_of_y[x] + dict_of_y_err[x]) for x in list_of_x],  # y2\n",
    "            color=color,\n",
    "            alpha=alpha,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598cc026",
   "metadata": {},
   "source": [
    "Define list of performance goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a577254",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_OF_GOALS = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 0.99, 1.00]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5bb8a",
   "metadata": {},
   "source": [
    "Iteration needed for MEAN + BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_average2: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_average2 = fig_plot_average2.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_average2.set_xlim(xmin=-0.005, xmax=1.005)\n",
    "axis_plot_average2.set_ylim(ymin=-1, ymax=101)\n",
    "\n",
    "# Plot average clustering performance evolution to reach 90% of vmeasure.\n",
    "MEAN_convergence_BEST_ANOVA_90, STDEV_convergence_BEST_ANOVA_90, SEM_convergence_BEST_ANOVA_90 = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if (\"simple_prep\" in env)\n",
    "        and (\"tfidf\" in env)\n",
    "        and (\"hier_avg\" in env)\n",
    "        and (\"closest\" in env)\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_average2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_BEST_ANOVA_90,\n",
    "    #dict_of_y_err=STDEV_convergence_BEST_ANOVA_90,\n",
    "    dict_of_y_err=SEM_convergence_BEST_ANOVA_90,\n",
    "    label=\"Moyenne des tentatives ayant le meilleur paramètrage moyen\\npour atteindre une annotation partielle (90% de v-measure).\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "    \n",
    "# Plot average clustering performance evolution to reach 100% of vmeasure.\n",
    "MEAN_convergence_BEST_ANOVA_100, STDEV_convergence_BEST_ANOVA_100, SEM_convergence_BEST_ANOVA_100 = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if (\"lemma_prep\" in env)\n",
    "        and (\"tfidf\" in env)\n",
    "        and (\"kmeans_COP\" in env)\n",
    "        and (\"closest\" in env)\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_average2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_BEST_ANOVA_100,\n",
    "    #dict_of_y_err=STDEV_convergence_BEST_ANOVA_100,\n",
    "    dict_of_y_err=SEM_convergence_BEST_ANOVA_100,\n",
    "    label=\"Moyenne des tentatives ayant le meilleur paramètrage moyen\\npour atteindre une annotation suffisante (100% de v-measure).\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution to reach constraints completude.\n",
    "MEAN_convergence_BEST_ANOVA_MAX, STDEV_convergence_BEST_ANOVA_MAX, SEM_convergence_BEST_ANOVA_MAX = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if (\"lemma_prep\" in env)\n",
    "        and (\"tfidf\" in env)\n",
    "        and (\"kmeans_COP\" in env)\n",
    "        and (\"in_same\" in env)\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_average2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_BEST_ANOVA_MAX,\n",
    "    #dict_of_y_err=STDEV_convergence_BEST_ANOVA_MAX,\n",
    "    dict_of_y_err=SEM_convergence_BEST_ANOVA_MAX,\n",
    "    label=\"Moyenne des tentatives ayant le meilleur paramètrage moyen\\npour atteindre une annotation exhaustive (toutes les contraintes).\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "MEAN_iteration_to_highlight_ALL, STDEV_iteration_to_highlight_ALL, SEM_iteration_to_highlight_ALL = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_average2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_iteration_to_highlight_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_iteration_to_highlight_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_average2.set_xlabel(\"v-measure [%]\", fontsize=18,)\n",
    "axis_plot_average2.set_ylabel(\"itération [#]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_average2.legend(loc=\"upper left\", fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_average2.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_average2.savefig(\n",
    "    \"../results/etude-efficience-evolution-moyenne-5best-par-vmeasure.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077257dd",
   "metadata": {},
   "source": [
    "Iteration needed for MEAN + PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_prep2: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_prep2 = fig_plot_prep2.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_prep2.set_xlim(xmin=-0.005, xmax=1.005)\n",
    "axis_plot_prep2.set_ylim(ymin=-1, ymax=101)\n",
    "\n",
    "# Plot average clustering performance evolution for no-prep.\n",
    "MEAN_convergence_no_prep, STDEV_convergence_no_prep, SEM_convergence_no_prep = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"no_prep\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_prep2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_no_prep,\n",
    "    #dict_of_y_err=STDEV_convergence_no_prep,\n",
    "    dict_of_y_err=SEM_convergence_no_prep,\n",
    "    label=\"Moyenne des tentatives avec le prétraitement 'prep.no'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for simple-prep.\n",
    "MEAN_convergence_simple_prep, STDEV_convergence_simple_prep, SEM_convergence_simple_prep = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"simple_prep\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_prep2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_simple_prep,\n",
    "    #dict_of_y_err=STDEV_convergence_simple_prep,\n",
    "    dict_of_y_err=SEM_convergence_simple_prep,\n",
    "    label=\"Moyenne des tentatives avec le prétraitement 'prep.simple'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for lemma-prep.\n",
    "MEAN_convergence_lemma_prep, STDEV_convergence_lemma_prep, SEM_convergence_lemma_prep = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"lemma_prep\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_prep2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_lemma_prep,\n",
    "    #dict_of_y_err=STDEV_convergence_lemma_prep,\n",
    "    dict_of_y_err=SEM_convergence_lemma_prep,\n",
    "    label=\"Moyenne des tentatives avec le prétraitement 'prep.lemma'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for filter-prep.\n",
    "MEAN_convergence_filter_prep, STDEV_convergence_filter_prep, SEM_convergence_filter_prep = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"filter_prep\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_prep2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_filter_prep,\n",
    "    #dict_of_y_err=STDEV_convergence_filter_prep,\n",
    "    dict_of_y_err=SEM_convergence_filter_prep,\n",
    "    label=\"Moyenne des tentatives avec le prétraitement 'prep.filter'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"orange\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "MEAN_convergence_ALL, STDEV_convergence_ALL, SEM_convergence_ALL = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_prep2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_convergence_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_prep2.set_xlabel(\"v-measure [%]\", fontsize=18,)\n",
    "axis_plot_prep2.set_ylabel(\"itération [#])\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_prep2.legend(loc=\"upper left\", fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_prep2.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_prep2.savefig(\n",
    "    \"../results/etude-efficience-evolution-moyenne-1preprocessing-par-vmeasure.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc35833",
   "metadata": {},
   "source": [
    "Iteration needed for MEAN + VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_vect2: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_vect2 = fig_plot_vect2.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_vect2.set_xlim(xmin=-0.005, xmax=1.005)\n",
    "axis_plot_vect2.set_ylim(ymin=-1, ymax=101)\n",
    "\n",
    "# Plot average clustering performance evolution for tfidf.\n",
    "MEAN_convergence_tfidf, STDEV_convergence_tfidf, SEM_convergence_tfidf = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"tfidf\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_vect2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_tfidf,\n",
    "    #dict_of_y_err=STDEV_convergence_tfidf,\n",
    "    dict_of_y_err=SEM_convergence_tfidf,\n",
    "    label=\"Moyenne des tentatives avec la vectorisation 'vect.tfidf'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for fr-core-news-md.\n",
    "MEAN_convergence_fr_core_news_md, STDEV_convergence_fr_core_news_md, SEM_convergence_fr_core_news_md = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"fr_core_news_md\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_vect2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_fr_core_news_md,\n",
    "    #dict_of_y_err=STDEV_convergence_fr_core_news_md,\n",
    "    dict_of_y_err=SEM_convergence_fr_core_news_md,\n",
    "    label=\"Moyenne des tentatives avec la vectorisation 'vect.frcorenewsmd'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "MEAN_convergence_ALL, STDEV_convergence_ALL, SEM_convergence_ALL = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_vect2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_convergence_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_vect2.set_xlabel(\"v-measure [%]\", fontsize=18,)\n",
    "axis_plot_vect2.set_ylabel(\"itération [#]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_vect2.legend(loc=\"upper left\", fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_vect2.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_vect2.savefig(\n",
    "    \"../results/etude-efficience-evolution-moyenne-2vectorization-par-vmeasure.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a9d34",
   "metadata": {},
   "source": [
    "Iteration needed for MEAN + CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a165ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_clust2: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_clust2 = fig_plot_clust2.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_clust2.set_xlim(xmin=-0.005, xmax=1.005)\n",
    "axis_plot_clust2.set_ylim(ymin=-1, ymax=101)\n",
    "\n",
    "# Plot average clustering performance evolution for kmeans_COP.\n",
    "MEAN_convergence_kmeans_COP, STDEV_convergence_kmeans_COP, SEM_convergence_kmeans_COP = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"kmeans_COP\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_clust2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_kmeans_COP,\n",
    "    #dict_of_y_err=STDEV_convergence_kmeans_COP,\n",
    "    dict_of_y_err=SEM_convergence_kmeans_COP,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.kmeans.cop'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for hier_sing.\n",
    "MEAN_convergence_hier_sing, STDEV_convergence_hier_sing, SEM_convergence_hier_sing = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"hier_sing\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_clust2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_hier_sing,\n",
    "    #dict_of_y_err=STDEV_convergence_hier_sing,\n",
    "    dict_of_y_err=SEM_convergence_hier_sing,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.hier.sing'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for hier_comp.\n",
    "MEAN_convergence_hier_comp, STDEV_convergence_hier_comp, SEM_convergence_hier_comp = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"hier_comp\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_clust2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_hier_comp,\n",
    "    #dict_of_y_err=STDEV_convergence_hier_comp,\n",
    "    dict_of_y_err=SEM_convergence_hier_comp,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.hier.comp'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "    \n",
    "# Plot average clustering performance evolution for hier_avg.\n",
    "MEAN_convergence_hier_avg, STDEV_convergence_hier_avg, SEM_convergence_hier_avg = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"hier_avg\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_clust2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_hier_avg,\n",
    "    #dict_of_y_err=STDEV_convergence_hier_avg,\n",
    "    dict_of_y_err=SEM_convergence_hier_avg,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.hier.avg'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"orange\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for hier_ward.\n",
    "MEAN_convergence_hier_ward, STDEV_convergence_hier_ward, SEM_convergence_hier_ward = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"hier_ward\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_clust2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_hier_ward,\n",
    "    #dict_of_y_err=STDEV_convergence_hier_ward,\n",
    "    dict_of_y_err=SEM_convergence_hier_ward,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.hier.ward'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"violet\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "    \n",
    "# Plot average clustering performance evolution for spectral_SPEC.\n",
    "MEAN_convergence_spectral_SPEC, STDEV_convergence_spectral_SPEC, SEM_convergence_spectral_SPEC = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"spectral_SPEC\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_clust2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_spectral_SPEC,\n",
    "    #dict_of_y_err=STDEV_convergence_spectral_SPEC,\n",
    "    dict_of_y_err=SEM_convergence_spectral_SPEC,\n",
    "    label=\"Moyenne des tentatives avec le clustering 'clust.spec'\",\n",
    "    marker=\"\",\n",
    "    markersize=3,\n",
    "    color=\"cyan\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "MEAN_convergence_ALL, STDEV_convergence_ALL, SEM_convergence_ALL = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_clust2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_convergence_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_clust2.set_xlabel(\"v-measure [%]\", fontsize=18,)\n",
    "axis_plot_clust2.set_ylabel(\"itération [#]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_clust2.legend(loc=\"upper left\", fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_clust2.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_clust2.savefig(\n",
    "    \"../results/etude-efficience-evolution-moyenne-3clustering-par-vmeasure.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ee17f",
   "metadata": {},
   "source": [
    "Iteration needed for MEAN + SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_samp2: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_samp2 = fig_plot_samp2.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_samp2.set_xlim(xmin=-0.005, xmax=1.005)\n",
    "axis_plot_samp2.set_ylim(ymin=-1, ymax=101)\n",
    "\n",
    "# Plot average clustering performance evolution for random.\n",
    "MEAN_convergence_random, STDEV_convergence_random, SEM_convergence_random = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"random\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_samp2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_random,\n",
    "    #dict_of_y_err=STDEV_convergence_random,\n",
    "    dict_of_y_err=SEM_convergence_random,\n",
    "    label=\"Moyenne des tentatives avec l'échantillonnage 'samp.random.full'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for random-in-same.\n",
    "MEAN_convergence_in_same, STDEV_convergence_in_same, SEM_convergence_in_same = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"in_same\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_samp2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_in_same,\n",
    "    #dict_of_y_err=STDEV_convergence_in_same,\n",
    "    dict_of_y_err=SEM_convergence_in_same,\n",
    "    label=\"Moyenne des tentatives avec l'échantillonnage 'samp.random.same'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for farthest.\n",
    "MEAN_convergence_farthest, STDEV_convergence_farthest, SEM_convergence_farthest = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"farthest\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_samp2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_farthest,\n",
    "    #dict_of_y_err=STDEV_convergence_farthest,\n",
    "    dict_of_y_err=SEM_convergence_farthest,\n",
    "    label=\"Moyenne des tentatives avec l'échantillonnage 'samp.farthest.same'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution for closest.\n",
    "MEAN_convergence_closest, STDEV_convergence_closest, SEM_convergence_closest = get_MEAN_SEM_of_iteration_needed_for_performance_goal(\n",
    "    local_LIST_OF_EXPERIMENT_ENVIRONMENTS=[\n",
    "        env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "        if \"closest\" in env\n",
    "    ],\n",
    "    local_LIST_OF_GOALS=LIST_OF_GOALS,\n",
    ")\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_samp2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_convergence_closest,\n",
    "    #dict_of_y_err=STDEV_convergence_closest,\n",
    "    dict_of_y_err=SEM_convergence_closest,\n",
    "    label=\"Moyenne des tentatives avec l'échantillonnage 'samp.closest.diff'\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"orange\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot average clustering performance evolution.\n",
    "add_plot_of_iteration_needed_per_performance_goal_to_graph(\n",
    "    axis=axis_plot_samp2,\n",
    "    list_of_x=LIST_OF_GOALS,\n",
    "    dict_of_y=MEAN_iteration_to_highlight_ALL,\n",
    "    #dict_of_y_err=STDEV_convergence_ALL,\n",
    "    dict_of_y_err=SEM_iteration_to_highlight_ALL,\n",
    "    label=\"Moyenne des tentatives\",\n",
    "    marker=\"\",\n",
    "    markersize=5,\n",
    "    color=\"black\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"-\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_samp2.set_xlabel(\"v-measure [%]\", fontsize=18,)\n",
    "axis_plot_samp2.set_ylabel(\"itération [#]\", fontsize=18,)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_samp2.legend(loc=\"upper left\", fontsize=15,)\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_samp2.grid(True)\n",
    "\n",
    "# Store the graph.\n",
    "fig_plot_samp2.savefig(\n",
    "    \"../results/etude-efficience-evolution-moyenne-4sampling-par-vmeasure.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
