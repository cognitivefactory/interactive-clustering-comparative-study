{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4554a785",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# ==== INTERACTIVE CLUSTERING : COMPUTATION TIME STUDY ====\n",
    "> ### Stage 3 : Apply main effects and post-hoc analysis on interactive clustering computation times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c329095",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc1fb5b",
   "metadata": {},
   "source": [
    "## READ-ME BEFORE RUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223164ec",
   "metadata": {},
   "source": [
    "### Quick Description\n",
    "\n",
    "This notebook is **aimed at run main effects and and post-hoc analysis on interactive clustering computation time over experiments**.\n",
    "- Environments are represented by subdirectories in the `/experiments` folder. A full path to an experiment environment is `/experiments/[TASK]/[DATASET]/[ALGORITHM]/`.\n",
    "- Experiments have to be run and evaluated in order to analyze convergency speed.\n",
    "\n",
    "Before running, **run the notebook `2_Estimate_computation_time.ipynb` to run each algorithm you have set**.\n",
    "\n",
    "Then, **go to the notebook `4_Plot_some_figures.ipynb` to create figures on interactive clustering computation time**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bec64b",
   "metadata": {},
   "source": [
    "### Description each steps\n",
    "\n",
    "First of all, **load experiment synthesis CSV file** that have been computed with the last notebook.\n",
    "- It contains parameters used for each experiment and convergency metric to compare.\n",
    "- Several parameters are studied depending on the task:\n",
    "    - _preprocessing_: `dataset_size`, `algorithm_name`;\n",
    "    - _vectorization_: `dataset_size`, `algorithm_name`;\n",
    "    - _sampling_: `dataset_size`, `algorithm_name`, `previous_nb_constraints`, `previous_nb_clusters`, `algorithm_nb_to_select`;\n",
    "    - _clustering_: `dataset_size`, `algorithm_name`, `previous_nb_constraints`, `previous_nb_clusters`.\n",
    "- Two random effects are used : `dataset_random_seed`, `algorithm_random_seed`.\n",
    "- One values is modelized with these factors : `time_total`.\n",
    "\n",
    "Then, for each task :\n",
    "1. First, **compute a global modelization** :\n",
    "    - Fit a generalized linear model (GLM) on data with all factors.\n",
    "2. Then, **evaluate the relevance of each factor** :\n",
    "    - Fit a generalized linear model (GLM) on data with all factors but without the factor you want to study.\n",
    "    - Perform parametric bootstrapping to evaluate the relevant of the studied factor.\n",
    "3. Finally, **compute a relevant modelization** :\n",
    "    - Fit a generalized linear model (GLM) on data with only relevant factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38ca28",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a5ca44",
   "metadata": {},
   "source": [
    "## 1. IMPORT R DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063124f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Le chargement a nécessité le package : Matrix\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#library(\"sjstats\")\n",
    "library(\"lme4\")\n",
    "library(\"emmeans\")\n",
    "library(\"pbnm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf881c2",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd54cb",
   "metadata": {},
   "source": [
    "## 2. ANALYSIS FOR PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e22a739",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "### 2.1. ANALYSIS FOR PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea13b2",
   "metadata": {},
   "source": [
    "#### 2.1.1. LOAD SYNTHESIS CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21bc697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analysis data.\n",
    "df_analysis_preprocessing <- read.csv(\n",
    "    file=\"../results/experiments_synthesis_for_preprocessing.csv\",\n",
    "    header=TRUE,  # Use the first row as headers.\n",
    "    sep=\";\",\n",
    "    skip=0,  # Number of rows to skip in the file.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc1c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column type.\n",
    "df_analysis_preprocessing$dataset_size <- as.numeric( df_analysis_preprocessing$dataset_size )\n",
    "df_analysis_preprocessing$dataset_random_seed <- as.numeric( df_analysis_preprocessing$dataset_random_seed )\n",
    "df_analysis_preprocessing$algorithm_name <- as.factor( df_analysis_preprocessing$algorithm_name )\n",
    "df_analysis_preprocessing$algorithm_random_seed <- as.numeric( df_analysis_preprocessing$algorithm_random_seed )\n",
    "df_analysis_preprocessing$time_total <- as.double( sub(\",\", \".\", df_analysis_preprocessing$time_total) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068a3220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 375 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>X</th><th scope=col>dataset_name</th><th scope=col>dataset_size</th><th scope=col>dataset_random_seed</th><th scope=col>algorithm_name</th><th scope=col>algorithm_random_seed</th><th scope=col>time_start</th><th scope=col>time_stop</th><th scope=col>time_total</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_1/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>filter_prep</td><td>1</td><td>1668606138</td><td>1668606148</td><td>10.645489</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_2/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>filter_prep</td><td>2</td><td>1668606138</td><td>1668606148</td><td>10.604682</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_3/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>filter_prep</td><td>3</td><td>1668606148</td><td>1668606155</td><td> 6.896929</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_4/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>filter_prep</td><td>4</td><td>1668606148</td><td>1668606155</td><td> 6.832410</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_5/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>filter_prep</td><td>5</td><td>1668606148</td><td>1668606155</td><td> 6.849232</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_1/ </td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>lemma_prep </td><td>1</td><td>1668606138</td><td>1668606148</td><td>10.631167</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_2/ </td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>lemma_prep </td><td>2</td><td>1668606138</td><td>1668606148</td><td>10.619905</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_3/ </td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>lemma_prep </td><td>3</td><td>1668606138</td><td>1668606148</td><td>10.423440</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_4/ </td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>lemma_prep </td><td>4</td><td>1668606148</td><td>1668606155</td><td> 6.854967</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_5/ </td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>lemma_prep </td><td>5</td><td>1668606148</td><td>1668606155</td><td> 6.806319</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_1/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>simple_prep</td><td>1</td><td>1668606138</td><td>1668606148</td><td>10.457545</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_2/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>simple_prep</td><td>2</td><td>1668606138</td><td>1668606148</td><td>10.408223</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_3/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>simple_prep</td><td>3</td><td>1668606138</td><td>1668606148</td><td>10.405806</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_4/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>simple_prep</td><td>4</td><td>1668606148</td><td>1668606155</td><td> 6.870062</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_5/</td><td>bank_cards_v2</td><td>1000</td><td>1</td><td>simple_prep</td><td>5</td><td>1668606148</td><td>1668606155</td><td> 6.768189</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_1/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>filter_prep</td><td>1</td><td>1668606155</td><td>1668606163</td><td> 7.570728</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_2/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>filter_prep</td><td>2</td><td>1668606155</td><td>1668606162</td><td> 6.614529</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_3/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>filter_prep</td><td>3</td><td>1668606155</td><td>1668606163</td><td> 7.414742</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_4/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>filter_prep</td><td>4</td><td>1668606162</td><td>1668606169</td><td> 6.801859</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_5/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>filter_prep</td><td>5</td><td>1668606163</td><td>1668606169</td><td> 6.823736</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_1/ </td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>lemma_prep </td><td>1</td><td>1668606155</td><td>1668606162</td><td> 7.357829</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_2/ </td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>lemma_prep </td><td>2</td><td>1668606155</td><td>1668606162</td><td> 7.483470</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_3/ </td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>lemma_prep </td><td>3</td><td>1668606155</td><td>1668606162</td><td> 6.625851</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_4/ </td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>lemma_prep </td><td>4</td><td>1668606162</td><td>1668606169</td><td> 6.874501</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_5/ </td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>lemma_prep </td><td>5</td><td>1668606162</td><td>1668606169</td><td> 6.762595</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_1/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>simple_prep</td><td>1</td><td>1668606148</td><td>1668606155</td><td> 6.867135</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_2/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>simple_prep</td><td>2</td><td>1668606155</td><td>1668606162</td><td> 6.669580</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_3/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>simple_prep</td><td>3</td><td>1668606155</td><td>1668606162</td><td> 6.735589</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_4/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>simple_prep</td><td>4</td><td>1668606162</td><td>1668606168</td><td> 6.668635</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_5/</td><td>bank_cards_v2</td><td>1000</td><td>2</td><td>simple_prep</td><td>5</td><td>1668606162</td><td>1668606169</td><td> 6.636718</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_1/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>filter_prep</td><td>1</td><td>1668606938</td><td>1668606971</td><td>32.87920</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_2/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>filter_prep</td><td>2</td><td>1668606951</td><td>1668606985</td><td>33.87764</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_3/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>filter_prep</td><td>3</td><td>1668606966</td><td>1668607001</td><td>34.50704</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_4/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>filter_prep</td><td>4</td><td>1668606979</td><td>1668607011</td><td>32.50550</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_5/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>filter_prep</td><td>5</td><td>1668606988</td><td>1668607021</td><td>32.59336</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_1/ </td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>lemma_prep </td><td>1</td><td>1668606937</td><td>1668606970</td><td>32.48344</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_2/ </td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>lemma_prep </td><td>2</td><td>1668606947</td><td>1668606979</td><td>32.67928</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_3/ </td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>lemma_prep </td><td>3</td><td>1668606956</td><td>1668606989</td><td>32.83009</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_4/ </td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>lemma_prep </td><td>4</td><td>1668606971</td><td>1668607005</td><td>34.07127</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_5/ </td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>lemma_prep </td><td>5</td><td>1668606985</td><td>1668607018</td><td>32.61983</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_1/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>simple_prep</td><td>1</td><td>1668606933</td><td>1668606966</td><td>33.03449</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_2/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>simple_prep</td><td>2</td><td>1668606946</td><td>1668606979</td><td>32.48548</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_3/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>simple_prep</td><td>3</td><td>1668606956</td><td>1668606988</td><td>32.47255</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_4/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>simple_prep</td><td>4</td><td>1668606970</td><td>1668607002</td><td>32.30569</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_5/</td><td>bank_cards_v2</td><td>5000</td><td>4</td><td>simple_prep</td><td>5</td><td>1668606980</td><td>1668607013</td><td>33.01613</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_1/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>filter_prep</td><td>1</td><td>1668607002</td><td>1668607034</td><td>32.22087</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_2/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>filter_prep</td><td>2</td><td>1668607013</td><td>1668607045</td><td>32.19430</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_3/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>filter_prep</td><td>3</td><td>1668607022</td><td>1668607055</td><td>33.07987</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_4/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>filter_prep</td><td>4</td><td>1668607038</td><td>1668607070</td><td>32.36726</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_5/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>filter_prep</td><td>5</td><td>1668607050</td><td>1668607082</td><td>31.53275</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_1/ </td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>lemma_prep </td><td>1</td><td>1668607001</td><td>1668607033</td><td>32.39641</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_2/ </td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>lemma_prep </td><td>2</td><td>1668607011</td><td>1668607043</td><td>31.61685</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_3/ </td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>lemma_prep </td><td>3</td><td>1668607021</td><td>1668607053</td><td>31.95513</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_4/ </td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>lemma_prep </td><td>4</td><td>1668607034</td><td>1668607066</td><td>31.41706</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_5/ </td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>lemma_prep </td><td>5</td><td>1668607045</td><td>1668607077</td><td>31.96743</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_1/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>simple_prep</td><td>1</td><td>1668606989</td><td>1668607022</td><td>32.58999</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_2/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>simple_prep</td><td>2</td><td>1668607005</td><td>1668607038</td><td>32.86239</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_3/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>simple_prep</td><td>3</td><td>1668607018</td><td>1668607050</td><td>32.59102</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_4/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>simple_prep</td><td>4</td><td>1668607033</td><td>1668607066</td><td>32.37850</td></tr>\n",
       "\t<tr><td>../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_5/</td><td>bank_cards_v2</td><td>5000</td><td>5</td><td>simple_prep</td><td>5</td><td>1668607043</td><td>1668607074</td><td>31.36368</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 375 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " X & dataset\\_name & dataset\\_size & dataset\\_random\\_seed & algorithm\\_name & algorithm\\_random\\_seed & time\\_start & time\\_stop & time\\_total\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <fct> & <dbl> & <int> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/filter\\_prep-rand\\_1/ & bank\\_cards\\_v2 & 1000 & 1 & filter\\_prep & 1 & 1668606138 & 1668606148 & 10.645489\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/filter\\_prep-rand\\_2/ & bank\\_cards\\_v2 & 1000 & 1 & filter\\_prep & 2 & 1668606138 & 1668606148 & 10.604682\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/filter\\_prep-rand\\_3/ & bank\\_cards\\_v2 & 1000 & 1 & filter\\_prep & 3 & 1668606148 & 1668606155 &  6.896929\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/filter\\_prep-rand\\_4/ & bank\\_cards\\_v2 & 1000 & 1 & filter\\_prep & 4 & 1668606148 & 1668606155 &  6.832410\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/filter\\_prep-rand\\_5/ & bank\\_cards\\_v2 & 1000 & 1 & filter\\_prep & 5 & 1668606148 & 1668606155 &  6.849232\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/lemma\\_prep-rand\\_1/  & bank\\_cards\\_v2 & 1000 & 1 & lemma\\_prep  & 1 & 1668606138 & 1668606148 & 10.631167\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/lemma\\_prep-rand\\_2/  & bank\\_cards\\_v2 & 1000 & 1 & lemma\\_prep  & 2 & 1668606138 & 1668606148 & 10.619905\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/lemma\\_prep-rand\\_3/  & bank\\_cards\\_v2 & 1000 & 1 & lemma\\_prep  & 3 & 1668606138 & 1668606148 & 10.423440\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/lemma\\_prep-rand\\_4/  & bank\\_cards\\_v2 & 1000 & 1 & lemma\\_prep  & 4 & 1668606148 & 1668606155 &  6.854967\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/lemma\\_prep-rand\\_5/  & bank\\_cards\\_v2 & 1000 & 1 & lemma\\_prep  & 5 & 1668606148 & 1668606155 &  6.806319\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/simple\\_prep-rand\\_1/ & bank\\_cards\\_v2 & 1000 & 1 & simple\\_prep & 1 & 1668606138 & 1668606148 & 10.457545\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/simple\\_prep-rand\\_2/ & bank\\_cards\\_v2 & 1000 & 1 & simple\\_prep & 2 & 1668606138 & 1668606148 & 10.408223\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/simple\\_prep-rand\\_3/ & bank\\_cards\\_v2 & 1000 & 1 & simple\\_prep & 3 & 1668606138 & 1668606148 & 10.405806\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/simple\\_prep-rand\\_4/ & bank\\_cards\\_v2 & 1000 & 1 & simple\\_prep & 4 & 1668606148 & 1668606155 &  6.870062\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_1/simple\\_prep-rand\\_5/ & bank\\_cards\\_v2 & 1000 & 1 & simple\\_prep & 5 & 1668606148 & 1668606155 &  6.768189\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/filter\\_prep-rand\\_1/ & bank\\_cards\\_v2 & 1000 & 2 & filter\\_prep & 1 & 1668606155 & 1668606163 &  7.570728\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/filter\\_prep-rand\\_2/ & bank\\_cards\\_v2 & 1000 & 2 & filter\\_prep & 2 & 1668606155 & 1668606162 &  6.614529\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/filter\\_prep-rand\\_3/ & bank\\_cards\\_v2 & 1000 & 2 & filter\\_prep & 3 & 1668606155 & 1668606163 &  7.414742\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/filter\\_prep-rand\\_4/ & bank\\_cards\\_v2 & 1000 & 2 & filter\\_prep & 4 & 1668606162 & 1668606169 &  6.801859\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/filter\\_prep-rand\\_5/ & bank\\_cards\\_v2 & 1000 & 2 & filter\\_prep & 5 & 1668606163 & 1668606169 &  6.823736\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/lemma\\_prep-rand\\_1/  & bank\\_cards\\_v2 & 1000 & 2 & lemma\\_prep  & 1 & 1668606155 & 1668606162 &  7.357829\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/lemma\\_prep-rand\\_2/  & bank\\_cards\\_v2 & 1000 & 2 & lemma\\_prep  & 2 & 1668606155 & 1668606162 &  7.483470\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/lemma\\_prep-rand\\_3/  & bank\\_cards\\_v2 & 1000 & 2 & lemma\\_prep  & 3 & 1668606155 & 1668606162 &  6.625851\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/lemma\\_prep-rand\\_4/  & bank\\_cards\\_v2 & 1000 & 2 & lemma\\_prep  & 4 & 1668606162 & 1668606169 &  6.874501\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/lemma\\_prep-rand\\_5/  & bank\\_cards\\_v2 & 1000 & 2 & lemma\\_prep  & 5 & 1668606162 & 1668606169 &  6.762595\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/simple\\_prep-rand\\_1/ & bank\\_cards\\_v2 & 1000 & 2 & simple\\_prep & 1 & 1668606148 & 1668606155 &  6.867135\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/simple\\_prep-rand\\_2/ & bank\\_cards\\_v2 & 1000 & 2 & simple\\_prep & 2 & 1668606155 & 1668606162 &  6.669580\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/simple\\_prep-rand\\_3/ & bank\\_cards\\_v2 & 1000 & 2 & simple\\_prep & 3 & 1668606155 & 1668606162 &  6.735589\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/simple\\_prep-rand\\_4/ & bank\\_cards\\_v2 & 1000 & 2 & simple\\_prep & 4 & 1668606162 & 1668606168 &  6.668635\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_1000-rand\\_2/simple\\_prep-rand\\_5/ & bank\\_cards\\_v2 & 1000 & 2 & simple\\_prep & 5 & 1668606162 & 1668606169 &  6.636718\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/filter\\_prep-rand\\_1/ & bank\\_cards\\_v2 & 5000 & 4 & filter\\_prep & 1 & 1668606938 & 1668606971 & 32.87920\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/filter\\_prep-rand\\_2/ & bank\\_cards\\_v2 & 5000 & 4 & filter\\_prep & 2 & 1668606951 & 1668606985 & 33.87764\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/filter\\_prep-rand\\_3/ & bank\\_cards\\_v2 & 5000 & 4 & filter\\_prep & 3 & 1668606966 & 1668607001 & 34.50704\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/filter\\_prep-rand\\_4/ & bank\\_cards\\_v2 & 5000 & 4 & filter\\_prep & 4 & 1668606979 & 1668607011 & 32.50550\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/filter\\_prep-rand\\_5/ & bank\\_cards\\_v2 & 5000 & 4 & filter\\_prep & 5 & 1668606988 & 1668607021 & 32.59336\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/lemma\\_prep-rand\\_1/  & bank\\_cards\\_v2 & 5000 & 4 & lemma\\_prep  & 1 & 1668606937 & 1668606970 & 32.48344\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/lemma\\_prep-rand\\_2/  & bank\\_cards\\_v2 & 5000 & 4 & lemma\\_prep  & 2 & 1668606947 & 1668606979 & 32.67928\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/lemma\\_prep-rand\\_3/  & bank\\_cards\\_v2 & 5000 & 4 & lemma\\_prep  & 3 & 1668606956 & 1668606989 & 32.83009\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/lemma\\_prep-rand\\_4/  & bank\\_cards\\_v2 & 5000 & 4 & lemma\\_prep  & 4 & 1668606971 & 1668607005 & 34.07127\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/lemma\\_prep-rand\\_5/  & bank\\_cards\\_v2 & 5000 & 4 & lemma\\_prep  & 5 & 1668606985 & 1668607018 & 32.61983\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/simple\\_prep-rand\\_1/ & bank\\_cards\\_v2 & 5000 & 4 & simple\\_prep & 1 & 1668606933 & 1668606966 & 33.03449\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/simple\\_prep-rand\\_2/ & bank\\_cards\\_v2 & 5000 & 4 & simple\\_prep & 2 & 1668606946 & 1668606979 & 32.48548\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/simple\\_prep-rand\\_3/ & bank\\_cards\\_v2 & 5000 & 4 & simple\\_prep & 3 & 1668606956 & 1668606988 & 32.47255\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/simple\\_prep-rand\\_4/ & bank\\_cards\\_v2 & 5000 & 4 & simple\\_prep & 4 & 1668606970 & 1668607002 & 32.30569\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_4/simple\\_prep-rand\\_5/ & bank\\_cards\\_v2 & 5000 & 4 & simple\\_prep & 5 & 1668606980 & 1668607013 & 33.01613\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/filter\\_prep-rand\\_1/ & bank\\_cards\\_v2 & 5000 & 5 & filter\\_prep & 1 & 1668607002 & 1668607034 & 32.22087\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/filter\\_prep-rand\\_2/ & bank\\_cards\\_v2 & 5000 & 5 & filter\\_prep & 2 & 1668607013 & 1668607045 & 32.19430\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/filter\\_prep-rand\\_3/ & bank\\_cards\\_v2 & 5000 & 5 & filter\\_prep & 3 & 1668607022 & 1668607055 & 33.07987\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/filter\\_prep-rand\\_4/ & bank\\_cards\\_v2 & 5000 & 5 & filter\\_prep & 4 & 1668607038 & 1668607070 & 32.36726\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/filter\\_prep-rand\\_5/ & bank\\_cards\\_v2 & 5000 & 5 & filter\\_prep & 5 & 1668607050 & 1668607082 & 31.53275\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/lemma\\_prep-rand\\_1/  & bank\\_cards\\_v2 & 5000 & 5 & lemma\\_prep  & 1 & 1668607001 & 1668607033 & 32.39641\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/lemma\\_prep-rand\\_2/  & bank\\_cards\\_v2 & 5000 & 5 & lemma\\_prep  & 2 & 1668607011 & 1668607043 & 31.61685\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/lemma\\_prep-rand\\_3/  & bank\\_cards\\_v2 & 5000 & 5 & lemma\\_prep  & 3 & 1668607021 & 1668607053 & 31.95513\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/lemma\\_prep-rand\\_4/  & bank\\_cards\\_v2 & 5000 & 5 & lemma\\_prep  & 4 & 1668607034 & 1668607066 & 31.41706\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/lemma\\_prep-rand\\_5/  & bank\\_cards\\_v2 & 5000 & 5 & lemma\\_prep  & 5 & 1668607045 & 1668607077 & 31.96743\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/simple\\_prep-rand\\_1/ & bank\\_cards\\_v2 & 5000 & 5 & simple\\_prep & 1 & 1668606989 & 1668607022 & 32.58999\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/simple\\_prep-rand\\_2/ & bank\\_cards\\_v2 & 5000 & 5 & simple\\_prep & 2 & 1668607005 & 1668607038 & 32.86239\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/simple\\_prep-rand\\_3/ & bank\\_cards\\_v2 & 5000 & 5 & simple\\_prep & 3 & 1668607018 & 1668607050 & 32.59102\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/simple\\_prep-rand\\_4/ & bank\\_cards\\_v2 & 5000 & 5 & simple\\_prep & 4 & 1668607033 & 1668607066 & 32.37850\\\\\n",
       "\t ../experiments/preprocessing/bank\\_cards\\_v2-size\\_5000-rand\\_5/simple\\_prep-rand\\_5/ & bank\\_cards\\_v2 & 5000 & 5 & simple\\_prep & 5 & 1668607043 & 1668607074 & 31.36368\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 375 × 9\n",
       "\n",
       "| X &lt;chr&gt; | dataset_name &lt;chr&gt; | dataset_size &lt;dbl&gt; | dataset_random_seed &lt;dbl&gt; | algorithm_name &lt;fct&gt; | algorithm_random_seed &lt;dbl&gt; | time_start &lt;int&gt; | time_stop &lt;int&gt; | time_total &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_1/ | bank_cards_v2 | 1000 | 1 | filter_prep | 1 | 1668606138 | 1668606148 | 10.645489 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_2/ | bank_cards_v2 | 1000 | 1 | filter_prep | 2 | 1668606138 | 1668606148 | 10.604682 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_3/ | bank_cards_v2 | 1000 | 1 | filter_prep | 3 | 1668606148 | 1668606155 |  6.896929 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_4/ | bank_cards_v2 | 1000 | 1 | filter_prep | 4 | 1668606148 | 1668606155 |  6.832410 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_5/ | bank_cards_v2 | 1000 | 1 | filter_prep | 5 | 1668606148 | 1668606155 |  6.849232 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_1/  | bank_cards_v2 | 1000 | 1 | lemma_prep  | 1 | 1668606138 | 1668606148 | 10.631167 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_2/  | bank_cards_v2 | 1000 | 1 | lemma_prep  | 2 | 1668606138 | 1668606148 | 10.619905 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_3/  | bank_cards_v2 | 1000 | 1 | lemma_prep  | 3 | 1668606138 | 1668606148 | 10.423440 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_4/  | bank_cards_v2 | 1000 | 1 | lemma_prep  | 4 | 1668606148 | 1668606155 |  6.854967 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_5/  | bank_cards_v2 | 1000 | 1 | lemma_prep  | 5 | 1668606148 | 1668606155 |  6.806319 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_1/ | bank_cards_v2 | 1000 | 1 | simple_prep | 1 | 1668606138 | 1668606148 | 10.457545 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_2/ | bank_cards_v2 | 1000 | 1 | simple_prep | 2 | 1668606138 | 1668606148 | 10.408223 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_3/ | bank_cards_v2 | 1000 | 1 | simple_prep | 3 | 1668606138 | 1668606148 | 10.405806 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_4/ | bank_cards_v2 | 1000 | 1 | simple_prep | 4 | 1668606148 | 1668606155 |  6.870062 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_5/ | bank_cards_v2 | 1000 | 1 | simple_prep | 5 | 1668606148 | 1668606155 |  6.768189 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_1/ | bank_cards_v2 | 1000 | 2 | filter_prep | 1 | 1668606155 | 1668606163 |  7.570728 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_2/ | bank_cards_v2 | 1000 | 2 | filter_prep | 2 | 1668606155 | 1668606162 |  6.614529 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_3/ | bank_cards_v2 | 1000 | 2 | filter_prep | 3 | 1668606155 | 1668606163 |  7.414742 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_4/ | bank_cards_v2 | 1000 | 2 | filter_prep | 4 | 1668606162 | 1668606169 |  6.801859 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_5/ | bank_cards_v2 | 1000 | 2 | filter_prep | 5 | 1668606163 | 1668606169 |  6.823736 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_1/  | bank_cards_v2 | 1000 | 2 | lemma_prep  | 1 | 1668606155 | 1668606162 |  7.357829 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_2/  | bank_cards_v2 | 1000 | 2 | lemma_prep  | 2 | 1668606155 | 1668606162 |  7.483470 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_3/  | bank_cards_v2 | 1000 | 2 | lemma_prep  | 3 | 1668606155 | 1668606162 |  6.625851 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_4/  | bank_cards_v2 | 1000 | 2 | lemma_prep  | 4 | 1668606162 | 1668606169 |  6.874501 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_5/  | bank_cards_v2 | 1000 | 2 | lemma_prep  | 5 | 1668606162 | 1668606169 |  6.762595 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_1/ | bank_cards_v2 | 1000 | 2 | simple_prep | 1 | 1668606148 | 1668606155 |  6.867135 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_2/ | bank_cards_v2 | 1000 | 2 | simple_prep | 2 | 1668606155 | 1668606162 |  6.669580 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_3/ | bank_cards_v2 | 1000 | 2 | simple_prep | 3 | 1668606155 | 1668606162 |  6.735589 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_4/ | bank_cards_v2 | 1000 | 2 | simple_prep | 4 | 1668606162 | 1668606168 |  6.668635 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_5/ | bank_cards_v2 | 1000 | 2 | simple_prep | 5 | 1668606162 | 1668606169 |  6.636718 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_1/ | bank_cards_v2 | 5000 | 4 | filter_prep | 1 | 1668606938 | 1668606971 | 32.87920 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_2/ | bank_cards_v2 | 5000 | 4 | filter_prep | 2 | 1668606951 | 1668606985 | 33.87764 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_3/ | bank_cards_v2 | 5000 | 4 | filter_prep | 3 | 1668606966 | 1668607001 | 34.50704 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_4/ | bank_cards_v2 | 5000 | 4 | filter_prep | 4 | 1668606979 | 1668607011 | 32.50550 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_5/ | bank_cards_v2 | 5000 | 4 | filter_prep | 5 | 1668606988 | 1668607021 | 32.59336 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_1/  | bank_cards_v2 | 5000 | 4 | lemma_prep  | 1 | 1668606937 | 1668606970 | 32.48344 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_2/  | bank_cards_v2 | 5000 | 4 | lemma_prep  | 2 | 1668606947 | 1668606979 | 32.67928 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_3/  | bank_cards_v2 | 5000 | 4 | lemma_prep  | 3 | 1668606956 | 1668606989 | 32.83009 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_4/  | bank_cards_v2 | 5000 | 4 | lemma_prep  | 4 | 1668606971 | 1668607005 | 34.07127 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_5/  | bank_cards_v2 | 5000 | 4 | lemma_prep  | 5 | 1668606985 | 1668607018 | 32.61983 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_1/ | bank_cards_v2 | 5000 | 4 | simple_prep | 1 | 1668606933 | 1668606966 | 33.03449 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_2/ | bank_cards_v2 | 5000 | 4 | simple_prep | 2 | 1668606946 | 1668606979 | 32.48548 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_3/ | bank_cards_v2 | 5000 | 4 | simple_prep | 3 | 1668606956 | 1668606988 | 32.47255 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_4/ | bank_cards_v2 | 5000 | 4 | simple_prep | 4 | 1668606970 | 1668607002 | 32.30569 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_5/ | bank_cards_v2 | 5000 | 4 | simple_prep | 5 | 1668606980 | 1668607013 | 33.01613 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_1/ | bank_cards_v2 | 5000 | 5 | filter_prep | 1 | 1668607002 | 1668607034 | 32.22087 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_2/ | bank_cards_v2 | 5000 | 5 | filter_prep | 2 | 1668607013 | 1668607045 | 32.19430 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_3/ | bank_cards_v2 | 5000 | 5 | filter_prep | 3 | 1668607022 | 1668607055 | 33.07987 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_4/ | bank_cards_v2 | 5000 | 5 | filter_prep | 4 | 1668607038 | 1668607070 | 32.36726 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_5/ | bank_cards_v2 | 5000 | 5 | filter_prep | 5 | 1668607050 | 1668607082 | 31.53275 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_1/  | bank_cards_v2 | 5000 | 5 | lemma_prep  | 1 | 1668607001 | 1668607033 | 32.39641 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_2/  | bank_cards_v2 | 5000 | 5 | lemma_prep  | 2 | 1668607011 | 1668607043 | 31.61685 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_3/  | bank_cards_v2 | 5000 | 5 | lemma_prep  | 3 | 1668607021 | 1668607053 | 31.95513 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_4/  | bank_cards_v2 | 5000 | 5 | lemma_prep  | 4 | 1668607034 | 1668607066 | 31.41706 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_5/  | bank_cards_v2 | 5000 | 5 | lemma_prep  | 5 | 1668607045 | 1668607077 | 31.96743 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_1/ | bank_cards_v2 | 5000 | 5 | simple_prep | 1 | 1668606989 | 1668607022 | 32.58999 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_2/ | bank_cards_v2 | 5000 | 5 | simple_prep | 2 | 1668607005 | 1668607038 | 32.86239 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_3/ | bank_cards_v2 | 5000 | 5 | simple_prep | 3 | 1668607018 | 1668607050 | 32.59102 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_4/ | bank_cards_v2 | 5000 | 5 | simple_prep | 4 | 1668607033 | 1668607066 | 32.37850 |\n",
       "| ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_5/ | bank_cards_v2 | 5000 | 5 | simple_prep | 5 | 1668607043 | 1668607074 | 31.36368 |\n",
       "\n"
      ],
      "text/plain": [
       "    X                                                                              \n",
       "1   ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_1/\n",
       "2   ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_2/\n",
       "3   ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_3/\n",
       "4   ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_4/\n",
       "5   ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/filter_prep-rand_5/\n",
       "6   ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_1/ \n",
       "7   ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_2/ \n",
       "8   ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_3/ \n",
       "9   ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_4/ \n",
       "10  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/lemma_prep-rand_5/ \n",
       "11  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_1/\n",
       "12  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_2/\n",
       "13  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_3/\n",
       "14  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_4/\n",
       "15  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_1/simple_prep-rand_5/\n",
       "16  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_1/\n",
       "17  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_2/\n",
       "18  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_3/\n",
       "19  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_4/\n",
       "20  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/filter_prep-rand_5/\n",
       "21  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_1/ \n",
       "22  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_2/ \n",
       "23  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_3/ \n",
       "24  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_4/ \n",
       "25  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/lemma_prep-rand_5/ \n",
       "26  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_1/\n",
       "27  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_2/\n",
       "28  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_3/\n",
       "29  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_4/\n",
       "30  ../experiments/preprocessing/bank_cards_v2-size_1000-rand_2/simple_prep-rand_5/\n",
       "⋮   ⋮                                                                              \n",
       "346 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_1/\n",
       "347 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_2/\n",
       "348 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_3/\n",
       "349 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_4/\n",
       "350 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/filter_prep-rand_5/\n",
       "351 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_1/ \n",
       "352 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_2/ \n",
       "353 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_3/ \n",
       "354 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_4/ \n",
       "355 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/lemma_prep-rand_5/ \n",
       "356 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_1/\n",
       "357 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_2/\n",
       "358 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_3/\n",
       "359 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_4/\n",
       "360 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_4/simple_prep-rand_5/\n",
       "361 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_1/\n",
       "362 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_2/\n",
       "363 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_3/\n",
       "364 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_4/\n",
       "365 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/filter_prep-rand_5/\n",
       "366 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_1/ \n",
       "367 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_2/ \n",
       "368 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_3/ \n",
       "369 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_4/ \n",
       "370 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/lemma_prep-rand_5/ \n",
       "371 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_1/\n",
       "372 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_2/\n",
       "373 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_3/\n",
       "374 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_4/\n",
       "375 ../experiments/preprocessing/bank_cards_v2-size_5000-rand_5/simple_prep-rand_5/\n",
       "    dataset_name  dataset_size dataset_random_seed algorithm_name\n",
       "1   bank_cards_v2 1000         1                   filter_prep   \n",
       "2   bank_cards_v2 1000         1                   filter_prep   \n",
       "3   bank_cards_v2 1000         1                   filter_prep   \n",
       "4   bank_cards_v2 1000         1                   filter_prep   \n",
       "5   bank_cards_v2 1000         1                   filter_prep   \n",
       "6   bank_cards_v2 1000         1                   lemma_prep    \n",
       "7   bank_cards_v2 1000         1                   lemma_prep    \n",
       "8   bank_cards_v2 1000         1                   lemma_prep    \n",
       "9   bank_cards_v2 1000         1                   lemma_prep    \n",
       "10  bank_cards_v2 1000         1                   lemma_prep    \n",
       "11  bank_cards_v2 1000         1                   simple_prep   \n",
       "12  bank_cards_v2 1000         1                   simple_prep   \n",
       "13  bank_cards_v2 1000         1                   simple_prep   \n",
       "14  bank_cards_v2 1000         1                   simple_prep   \n",
       "15  bank_cards_v2 1000         1                   simple_prep   \n",
       "16  bank_cards_v2 1000         2                   filter_prep   \n",
       "17  bank_cards_v2 1000         2                   filter_prep   \n",
       "18  bank_cards_v2 1000         2                   filter_prep   \n",
       "19  bank_cards_v2 1000         2                   filter_prep   \n",
       "20  bank_cards_v2 1000         2                   filter_prep   \n",
       "21  bank_cards_v2 1000         2                   lemma_prep    \n",
       "22  bank_cards_v2 1000         2                   lemma_prep    \n",
       "23  bank_cards_v2 1000         2                   lemma_prep    \n",
       "24  bank_cards_v2 1000         2                   lemma_prep    \n",
       "25  bank_cards_v2 1000         2                   lemma_prep    \n",
       "26  bank_cards_v2 1000         2                   simple_prep   \n",
       "27  bank_cards_v2 1000         2                   simple_prep   \n",
       "28  bank_cards_v2 1000         2                   simple_prep   \n",
       "29  bank_cards_v2 1000         2                   simple_prep   \n",
       "30  bank_cards_v2 1000         2                   simple_prep   \n",
       "⋮   ⋮             ⋮            ⋮                   ⋮             \n",
       "346 bank_cards_v2 5000         4                   filter_prep   \n",
       "347 bank_cards_v2 5000         4                   filter_prep   \n",
       "348 bank_cards_v2 5000         4                   filter_prep   \n",
       "349 bank_cards_v2 5000         4                   filter_prep   \n",
       "350 bank_cards_v2 5000         4                   filter_prep   \n",
       "351 bank_cards_v2 5000         4                   lemma_prep    \n",
       "352 bank_cards_v2 5000         4                   lemma_prep    \n",
       "353 bank_cards_v2 5000         4                   lemma_prep    \n",
       "354 bank_cards_v2 5000         4                   lemma_prep    \n",
       "355 bank_cards_v2 5000         4                   lemma_prep    \n",
       "356 bank_cards_v2 5000         4                   simple_prep   \n",
       "357 bank_cards_v2 5000         4                   simple_prep   \n",
       "358 bank_cards_v2 5000         4                   simple_prep   \n",
       "359 bank_cards_v2 5000         4                   simple_prep   \n",
       "360 bank_cards_v2 5000         4                   simple_prep   \n",
       "361 bank_cards_v2 5000         5                   filter_prep   \n",
       "362 bank_cards_v2 5000         5                   filter_prep   \n",
       "363 bank_cards_v2 5000         5                   filter_prep   \n",
       "364 bank_cards_v2 5000         5                   filter_prep   \n",
       "365 bank_cards_v2 5000         5                   filter_prep   \n",
       "366 bank_cards_v2 5000         5                   lemma_prep    \n",
       "367 bank_cards_v2 5000         5                   lemma_prep    \n",
       "368 bank_cards_v2 5000         5                   lemma_prep    \n",
       "369 bank_cards_v2 5000         5                   lemma_prep    \n",
       "370 bank_cards_v2 5000         5                   lemma_prep    \n",
       "371 bank_cards_v2 5000         5                   simple_prep   \n",
       "372 bank_cards_v2 5000         5                   simple_prep   \n",
       "373 bank_cards_v2 5000         5                   simple_prep   \n",
       "374 bank_cards_v2 5000         5                   simple_prep   \n",
       "375 bank_cards_v2 5000         5                   simple_prep   \n",
       "    algorithm_random_seed time_start time_stop  time_total\n",
       "1   1                     1668606138 1668606148 10.645489 \n",
       "2   2                     1668606138 1668606148 10.604682 \n",
       "3   3                     1668606148 1668606155  6.896929 \n",
       "4   4                     1668606148 1668606155  6.832410 \n",
       "5   5                     1668606148 1668606155  6.849232 \n",
       "6   1                     1668606138 1668606148 10.631167 \n",
       "7   2                     1668606138 1668606148 10.619905 \n",
       "8   3                     1668606138 1668606148 10.423440 \n",
       "9   4                     1668606148 1668606155  6.854967 \n",
       "10  5                     1668606148 1668606155  6.806319 \n",
       "11  1                     1668606138 1668606148 10.457545 \n",
       "12  2                     1668606138 1668606148 10.408223 \n",
       "13  3                     1668606138 1668606148 10.405806 \n",
       "14  4                     1668606148 1668606155  6.870062 \n",
       "15  5                     1668606148 1668606155  6.768189 \n",
       "16  1                     1668606155 1668606163  7.570728 \n",
       "17  2                     1668606155 1668606162  6.614529 \n",
       "18  3                     1668606155 1668606163  7.414742 \n",
       "19  4                     1668606162 1668606169  6.801859 \n",
       "20  5                     1668606163 1668606169  6.823736 \n",
       "21  1                     1668606155 1668606162  7.357829 \n",
       "22  2                     1668606155 1668606162  7.483470 \n",
       "23  3                     1668606155 1668606162  6.625851 \n",
       "24  4                     1668606162 1668606169  6.874501 \n",
       "25  5                     1668606162 1668606169  6.762595 \n",
       "26  1                     1668606148 1668606155  6.867135 \n",
       "27  2                     1668606155 1668606162  6.669580 \n",
       "28  3                     1668606155 1668606162  6.735589 \n",
       "29  4                     1668606162 1668606168  6.668635 \n",
       "30  5                     1668606162 1668606169  6.636718 \n",
       "⋮   ⋮                     ⋮          ⋮          ⋮         \n",
       "346 1                     1668606938 1668606971 32.87920  \n",
       "347 2                     1668606951 1668606985 33.87764  \n",
       "348 3                     1668606966 1668607001 34.50704  \n",
       "349 4                     1668606979 1668607011 32.50550  \n",
       "350 5                     1668606988 1668607021 32.59336  \n",
       "351 1                     1668606937 1668606970 32.48344  \n",
       "352 2                     1668606947 1668606979 32.67928  \n",
       "353 3                     1668606956 1668606989 32.83009  \n",
       "354 4                     1668606971 1668607005 34.07127  \n",
       "355 5                     1668606985 1668607018 32.61983  \n",
       "356 1                     1668606933 1668606966 33.03449  \n",
       "357 2                     1668606946 1668606979 32.48548  \n",
       "358 3                     1668606956 1668606988 32.47255  \n",
       "359 4                     1668606970 1668607002 32.30569  \n",
       "360 5                     1668606980 1668607013 33.01613  \n",
       "361 1                     1668607002 1668607034 32.22087  \n",
       "362 2                     1668607013 1668607045 32.19430  \n",
       "363 3                     1668607022 1668607055 33.07987  \n",
       "364 4                     1668607038 1668607070 32.36726  \n",
       "365 5                     1668607050 1668607082 31.53275  \n",
       "366 1                     1668607001 1668607033 32.39641  \n",
       "367 2                     1668607011 1668607043 31.61685  \n",
       "368 3                     1668607021 1668607053 31.95513  \n",
       "369 4                     1668607034 1668607066 31.41706  \n",
       "370 5                     1668607045 1668607077 31.96743  \n",
       "371 1                     1668606989 1668607022 32.58999  \n",
       "372 2                     1668607005 1668607038 32.86239  \n",
       "373 3                     1668607018 1668607050 32.59102  \n",
       "374 4                     1668607033 1668607066 32.37850  \n",
       "375 5                     1668607043 1668607074 31.36368  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show an extract of analysis data.\n",
    "df_analysis_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6066b161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subsets by algorithm_name.\n",
    "df_analysis_preprocessing_simple_prep <- df_analysis_preprocessing[df_analysis_preprocessing$algorithm_name==\"simple_prep\",]\n",
    "df_analysis_preprocessing_lemma_prep <- df_analysis_preprocessing[df_analysis_preprocessing$algorithm_name==\"lemma_prep\",]\n",
    "df_analysis_preprocessing_filter_prep <- df_analysis_preprocessing[df_analysis_preprocessing$algorithm_name==\"filter_prep\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "#### 2.1.2. Apply general analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059428ce",
   "metadata": {},
   "source": [
    "Fit a generalized linear models (GLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f71452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Some predictor variables are on very different scales: consider rescaling\"\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GLM_fit_preprocessing_FULL <- lmer(\n",
    "    formula = time_total ~ algorithm_name + dataset_size + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_preprocessing\n",
    ")\n",
    "GLM_fit_preprocessing_FULL_WITHOUT_dataset_size <- lmer(\n",
    "    formula = time_total ~ algorithm_name + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_preprocessing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23e8a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "refitting model(s) with ML (instead of REML)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      npar           AIC              BIC             logLik     \n",
       " Min.   :6.00   Min.   : 737.9   Min.   : 765.4   Min.   :-1354  \n",
       " 1st Qu.:6.25   1st Qu.:1233.4   1st Qu.:1259.9   1st Qu.:-1106  \n",
       " Median :6.50   Median :1728.9   Median :1754.5   Median : -858  \n",
       " Mean   :6.50   Mean   :1728.9   Mean   :1754.5   Mean   : -858  \n",
       " 3rd Qu.:6.75   3rd Qu.:2224.5   3rd Qu.:2249.0   3rd Qu.: -610  \n",
       " Max.   :7.00   Max.   :2720.0   Max.   :2743.5   Max.   : -362  \n",
       "                                                                 \n",
       "    deviance          Chisq            Df      Pr(>Chisq)\n",
       " Min.   : 723.9   Min.   :1984   Min.   :1   Min.   :0   \n",
       " 1st Qu.:1219.9   1st Qu.:1984   1st Qu.:1   1st Qu.:0   \n",
       " Median :1715.9   Median :1984   Median :1   Median :0   \n",
       " Mean   :1715.9   Mean   :1984   Mean   :1   Mean   :0   \n",
       " 3rd Qu.:2212.0   3rd Qu.:1984   3rd Qu.:1   3rd Qu.:0   \n",
       " Max.   :2708.0   Max.   :1984   Max.   :1   Max.   :0   \n",
       "                  NA's   :1      NA's   :1   NA's   :1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(anova(GLM_fit_preprocessing_FULL, GLM_fit_preprocessing_FULL_WITHOUT_dataset_size, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f583b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Some predictor variables are on very different scales: consider rescaling\"\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "Warning message:\n",
      "\"Some predictor variables are on very different scales: consider rescaling\"\n",
      "Warning message:\n",
      "\"Some predictor variables are on very different scales: consider rescaling\"\n"
     ]
    }
   ],
   "source": [
    "GLM_fit_preprocessing_ALGONAME_simple_prep <- lmer(\n",
    "    formula = time_total ~ dataset_size + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_preprocessing_simple_prep\n",
    ")\n",
    "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_size <- lmer(\n",
    "    formula = time_total ~ (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_preprocessing_simple_prep\n",
    ")\n",
    "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed <- lmer(\n",
    "    formula = time_total ~ dataset_size + ( 1 | algorithm_random_seed ),\n",
    "    data = df_analysis_preprocessing_simple_prep\n",
    ")\n",
    "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_algorithm_random_seed <- lmer(\n",
    "    formula = time_total ~ dataset_size + ( 1 | dataset_random_seed ),\n",
    "    data = df_analysis_preprocessing_simple_prep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07b0b074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "refitting model(s) with ML (instead of REML)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A anova: 2 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>npar</th><th scope=col>AIC</th><th scope=col>BIC</th><th scope=col>logLik</th><th scope=col>deviance</th><th scope=col>Chisq</th><th scope=col>Df</th><th scope=col>Pr(&gt;Chisq)</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed</th><td>4</td><td>258.2088</td><td>269.5220</td><td>-125.1044</td><td>250.2088</td><td>      NA</td><td>NA</td><td>         NA</td></tr>\n",
       "\t<tr><th scope=row>GLM_fit_preprocessing_ALGONAME_simple_prep</th><td>5</td><td>250.8383</td><td>264.9799</td><td>-120.4192</td><td>240.8383</td><td>9.370441</td><td> 1</td><td>0.002205125</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A anova: 2 × 8\n",
       "\\begin{tabular}{r|llllllll}\n",
       "  & npar & AIC & BIC & logLik & deviance & Chisq & Df & Pr(>Chisq)\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tGLM\\_fit\\_preprocessing\\_ALGONAME\\_simple\\_prep\\_WITHOUT\\_dataset\\_random\\_seed & 4 & 258.2088 & 269.5220 & -125.1044 & 250.2088 &       NA & NA &          NA\\\\\n",
       "\tGLM\\_fit\\_preprocessing\\_ALGONAME\\_simple\\_prep & 5 & 250.8383 & 264.9799 & -120.4192 & 240.8383 & 9.370441 &  1 & 0.002205125\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A anova: 2 × 8\n",
       "\n",
       "| <!--/--> | npar &lt;dbl&gt; | AIC &lt;dbl&gt; | BIC &lt;dbl&gt; | logLik &lt;dbl&gt; | deviance &lt;dbl&gt; | Chisq &lt;dbl&gt; | Df &lt;dbl&gt; | Pr(&gt;Chisq) &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed | 4 | 258.2088 | 269.5220 | -125.1044 | 250.2088 |       NA | NA |          NA |\n",
       "| GLM_fit_preprocessing_ALGONAME_simple_prep | 5 | 250.8383 | 264.9799 | -120.4192 | 240.8383 | 9.370441 |  1 | 0.002205125 |\n",
       "\n"
      ],
      "text/plain": [
       "                                                                       npar\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed 4   \n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep                             5   \n",
       "                                                                       AIC     \n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed 258.2088\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep                             250.8383\n",
       "                                                                       BIC     \n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed 269.5220\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep                             264.9799\n",
       "                                                                       logLik   \n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed -125.1044\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep                             -120.4192\n",
       "                                                                       deviance\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed 250.2088\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep                             240.8383\n",
       "                                                                       Chisq   \n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed       NA\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep                             9.370441\n",
       "                                                                       Df\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed NA\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep                              1\n",
       "                                                                       Pr(>Chisq) \n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed          NA\n",
       "GLM_fit_preprocessing_ALGONAME_simple_prep                             0.002205125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(GLM_fit_preprocessing_ALGONAME_simple_prep, GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_dataset_random_seed, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e74f06a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Some predictor variables are on very different scales: consider rescaling\"\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GLM_fit_preprocessing_ALGONAME_lemma_prep <- lmer(\n",
    "    formula = time_total ~ dataset_size + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_preprocessing_lemma_prep\n",
    ")\n",
    "GLM_fit_preprocessing_ALGONAME_lemma_prep_WITHOUT_dataset_size <- lmer(\n",
    "    formula = time_total ~ (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_preprocessing_lemma_prep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c9e9afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear mixed model fit by REML ['lmerMod']\n",
       "Formula: time_total ~ dataset_size + (1 | dataset_random_seed)\n",
       "   Data: df_analysis_preprocessing_simple_prep\n",
       "\n",
       "REML criterion at convergence: 261.7\n",
       "\n",
       "Scaled residuals: \n",
       "    Min      1Q  Median      3Q     Max \n",
       "-1.5547 -0.5997 -0.1386  0.3384  4.6116 \n",
       "\n",
       "Random effects:\n",
       " Groups              Name        Variance Std.Dev.\n",
       " dataset_random_seed (Intercept) 0.07243  0.2691  \n",
       " Residual                        0.38151  0.6177  \n",
       "Number of obs: 125, groups:  dataset_random_seed, 5\n",
       "\n",
       "Fixed effects:\n",
       "              Estimate Std. Error t value\n",
       "(Intercept)  8.695e-01  1.768e-01   4.917\n",
       "dataset_size 6.317e-03  3.906e-05 161.701\n",
       "\n",
       "Correlation of Fixed Effects:\n",
       "            (Intr)\n",
       "dataset_siz -0.663\n",
       "fit warnings:\n",
       "Some predictor variables are on very different scales: consider rescaling"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(GLM_fit_preprocessing_ALGONAME_simple_prep_WITHOUT_algorithm_random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07537fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Some predictor variables are on very different scales: consider rescaling\"\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GLM_fit_preprocessing_ALGONAME_filter_prep <- lmer(\n",
    "    formula = time_total ~ dataset_size + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_preprocessing_filter_prep\n",
    ")\n",
    "GLM_fit_preprocessing_ALGONAME_filter_prep_WITHOUT_dataset_size <- lmer(\n",
    "    formula = time_total ~ (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_preprocessing_filter_prep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cbf249",
   "metadata": {
    "raw_mimetype": "r"
   },
   "outputs": [],
   "source": [
    "# drop1(GLM_fit_preprocessing, test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c562a64f",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `algorithm_name` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e45db138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"Some predictor variables are on very different scales: consider rescaling\"\n",
      "refitting model(s) with ML (instead of REML)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      npar          AIC             BIC            logLik        deviance    \n",
       " Min.   :5.0   Min.   :734.1   Min.   :753.7   Min.   :-362   Min.   :723.9  \n",
       " 1st Qu.:5.5   1st Qu.:735.0   1st Qu.:756.6   1st Qu.:-362   1st Qu.:723.9  \n",
       " Median :6.0   Median :736.0   Median :759.5   Median :-362   Median :724.0  \n",
       " Mean   :6.0   Mean   :736.0   Mean   :759.5   Mean   :-362   Mean   :724.0  \n",
       " 3rd Qu.:6.5   3rd Qu.:736.9   3rd Qu.:762.5   3rd Qu.:-362   3rd Qu.:724.0  \n",
       " Max.   :7.0   Max.   :737.9   Max.   :765.4   Max.   :-362   Max.   :724.1  \n",
       "                                                                             \n",
       "     Chisq             Df      Pr(>Chisq)    \n",
       " Min.   :0.153   Min.   :2   Min.   :0.9264  \n",
       " 1st Qu.:0.153   1st Qu.:2   1st Qu.:0.9264  \n",
       " Median :0.153   Median :2   Median :0.9264  \n",
       " Mean   :0.153   Mean   :2   Mean   :0.9264  \n",
       " 3rd Qu.:0.153   3rd Qu.:2   3rd Qu.:0.9264  \n",
       " Max.   :0.153   Max.   :2   Max.   :0.9264  \n",
       " NA's   :1       NA's   :1   NA's   :1       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# pbgmm_preprocessing_without_algorithm_name <- pbnm( GLM_fit_preprocessing, GLM_fit_preprocessing_without_algorithm_name, nsim=1000, tasks=10, cores=2, seed=42 ) \n",
    "# summary(pbgmm_preprocessing_without_algorithm_name)\n",
    "anova_preprocessing_without_algorithm_name <- anova(GLM_fit_preprocessing, GLM_fit_preprocessing_without_algorithm_name, test=\"Chisq\")\n",
    "summary(anova_preprocessing_without_algorithm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8581610",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `dataset_size` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526f4cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parametric bootstrap testing: dataset_size = 0 \n",
       "from: glm(formula = time_total ~ algorithm_name + dataset_size + (1 |  dataset_random_seed) + (1 | algorithm_random_seed), data = df_analysis_preprocessing) \n",
       "1000 samples were taken Tue Mar 14 13:15:01 2023 \n",
       "1000 samples had errors, 1000 in alternate model 1000 in null model \n",
       "1000 unused samples.  0 <= P(abs(dataset_size) > |0.006311287|) <= 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "pbgmm_preprocessing_without_dataset_size <- pbnm( GLM_fit_preprocessing, GLM_fit_preprocessing_without_dataset_size, nsim=1000, tasks=10, cores=2, seed=42 ) \n",
    "summary(pbgmm_preprocessing_without_dataset_size)\n",
    "#anova_preprocessing_without_dataset_size <- anova(GLM_fit_preprocessing, GLM_fit_preprocessing_without_dataset_size, test=\"Chisq\")\n",
    "#summary(anova_preprocessing_without_dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497986f7",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `dataset_random_seed` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8d1908",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in UseMethod(\"VarCorr\"): pas de méthode pour 'VarCorr' applicable pour un objet de classe \"c('glm', 'lm')\"\n",
     "output_type": "error",
     "traceback": [
      "Error in UseMethod(\"VarCorr\"): pas de méthode pour 'VarCorr' applicable pour un objet de classe \"c('glm', 'lm')\"\nTraceback:\n",
      "1. pbnm(GLM_fit_preprocessing, GLM_fit_preprocessing_without_dataset_random_seed, \n .     nsim = 1000, tasks = 10, cores = 2, seed = 42)",
      "2. pbnmRD(m1 = m1, m0 = m0, nsim = nsim, cores = cores, tasks = tasks, \n .     seed = seed, test = test, progress = progress, nestStat = nestStat, \n .     callEnvir = callEnvir, matchCall = mc)",
      "3. termInd(m1, testTerms)",
      "4. lme4::VarCorr(mod)"
     ]
    }
   ],
   "source": [
    "GLM_fit_preprocessing_without_dataset_random_seed <- glm(\n",
    "    formula = time_total ~ algorithm_name + dataset_size + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_preprocessing\n",
    ")\n",
    "pbgmm_preprocessing_without_dataset_random_seed <- pbnm( GLM_fit_preprocessing, GLM_fit_preprocessing_without_dataset_random_seed, nsim=1000, tasks=10, cores=2, seed=42 ) \n",
    "summary(pbgmm_preprocessing_without_dataset_random_seed)\n",
    "#diff_preprocessing_without_dataset_random_seed = logLik(GLM_fit_preprocessing) - logLik(GLM_fit_preprocessing_without_dataset_random_seed)\n",
    "#pchisq(as.numeric(diff_preprocessing_without_dataset_random_seed), df=1, lower.tail=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3442ee",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `algorithm_random_seed` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ae513",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_fit_preprocessing_without_algorithm_random_seed <- glm(\n",
    "    formula = time_total ~ algorithm_name + dataset_size + (1 | dataset_random_seed),\n",
    "    data = df_analysis_preprocessing\n",
    ")\n",
    "# pbgmm_preprocessing_without_algorithm_random_seed <- pbnm( GLM_fit_preprocessing, GLM_fit_preprocessing_without_algorithm_random_seed, nsim=1000, tasks=10, cores=2, seed=42 ) \n",
    "# summary(pbgmm_preprocessing_without_algorithm_random_seed)\n",
    "diff_preprocessing_without_algorithm_random_seed = logLik(GLM_fit_preprocessing) - logLik(GLM_fit_preprocessing_without_algorithm_random_seed)\n",
    "pchisq(as.numeric(diff_preprocessing_without_algorithm_random_seed), df=1, lower.tail=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff827c",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51edbbf",
   "metadata": {},
   "source": [
    "### 2.2. ANALYSIS FOR VECTORIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562875e",
   "metadata": {},
   "source": [
    "#### 2.2.1. LOAD SYNTHESIS CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analysis data.\n",
    "df_analysis_vectorization <- read.csv(\n",
    "    file=\"../results/experiments_synthesis_for_vectorization.csv\",\n",
    "    header=TRUE,  # Use the first row as headers.\n",
    "    sep=\";\",\n",
    "    skip=0,  # Number of rows to skip in the file.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b09f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column type.\n",
    "df_analysis_vectorization$dataset_size <- as.numeric( df_analysis_vectorization$dataset_size )\n",
    "df_analysis_vectorization$dataset_random_seed <- as.numeric( df_analysis_vectorization$dataset_random_seed )\n",
    "df_analysis_vectorization$algorithm_name <- as.factor( df_analysis_vectorization$algorithm_name )\n",
    "df_analysis_vectorization$algorithm_random_seed <- as.numeric( df_analysis_vectorization$algorithm_random_seed )\n",
    "df_analysis_vectorization$time_total <- as.double( sub(\",\", \".\", df_analysis_vectorization$time_total) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89c0d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show an extract of analysis data.\n",
    "df_analysis_vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3a2347",
   "metadata": {},
   "source": [
    "#### 2.2.2. Apply general analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9dbaae",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07caf525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GLM_fit_vectorization <- glm(\n",
    "    formula = time_total ~ algorithm_name + dataset_size + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_vectorization\n",
    ")\n",
    "summary(GLM_fit_vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843673e",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `algorithm_name` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_fit_vectorization_without_algorithm_name <- glm(\n",
    "    formula = time_total ~ dataset_size + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_vectorization\n",
    ")\n",
    "# pbgmm_vectorization_without_algorithm_name <- pbnm( GLM_fit_vectorization, GLM_fit_vectorization_without_algorithm_name, nsim=1000, tasks=10, cores=2, seed=42 ) \n",
    "# summary(pbgmm_vectorization_without_algorithm_name)\n",
    "anova_vectorization_without_algorithm_name <- anova(GLM_fit_vectorization, GLM_fit_vectorization_without_algorithm_name, test=\"Chisq\")\n",
    "summary(anova_vectorization_without_algorithm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ed58d",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `dataset_size` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_fit_vectorization_without_dataset_size <- glm(\n",
    "    formula = time_total ~ algorithm_name + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_vectorization\n",
    ")\n",
    "# pbgmm_vectorization_without_dataset_size <- pbnm( GLM_fit_vectorization, GLM_fit_vectorization_without_dataset_size, nsim=1000, tasks=10, cores=2, seed=42 )\n",
    "# summary(pbgmm_vectorization_without_dataset_size)\n",
    "anova_vectorization_without_dataset_size <- anova(GLM_fit_vectorization, GLM_fit_vectorization_without_dataset_size, test=\"Chisq\")\n",
    "summary(anova_vectorization_without_dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bc162a",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f49f0",
   "metadata": {},
   "source": [
    "### 2.3. ANALYSIS FOR SAMPLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff61adb5",
   "metadata": {},
   "source": [
    "#### 2.3.1. LOAD SYNTHESIS CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analysis data.\n",
    "df_analysis_sampling <- read.csv(\n",
    "    file=\"../results/experiments_synthesis_for_sampling.csv\",\n",
    "    header=TRUE,  # Use the first row as headers.\n",
    "    sep=\";\",\n",
    "    skip=0,  # Number of rows to skip in the file.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column type.\n",
    "df_analysis_sampling$dataset_size <- as.numeric( df_analysis_sampling$dataset_size )\n",
    "df_analysis_sampling$dataset_random_seed <- as.numeric( df_analysis_sampling$dataset_random_seed )\n",
    "df_analysis_sampling$previous_nb_constraints <- as.numeric( df_analysis_sampling$previous_nb_constraints )\n",
    "df_analysis_sampling$previous_nb_clusters <- as.numeric( df_analysis_sampling$previous_nb_clusters )\n",
    "df_analysis_sampling$algorithm_name <- as.factor( df_analysis_sampling$algorithm_name )\n",
    "df_analysis_sampling$algorithm_random_seed <- as.numeric( df_analysis_sampling$algorithm_random_seed )\n",
    "df_analysis_sampling$algorithm_nb_to_select <- as.numeric( df_analysis_sampling$algorithm_nb_to_select )\n",
    "df_analysis_sampling$time_total <- as.double( sub(\",\", \".\", df_analysis_sampling$time_total) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d80e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show an extract of analysis data.\n",
    "df_analysis_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843973f",
   "metadata": {},
   "source": [
    "#### 2.3.2. Apply general analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48960c3b",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9b344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GLM_fit_sampling <- glm(\n",
    "    formula = time_total ~ algorithm_name + dataset_size + previous_nb_constraints + previous_nb_clusters + algorithm_nb_to_select + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_sampling\n",
    ")\n",
    "summary(GLM_fit_sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff65bc4",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `algorithm_name` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6834af",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_fit_sampling_without_algorithm_name <- glm(\n",
    "    formula = time_total ~ dataset_size + previous_nb_constraints + previous_nb_clusters + algorithm_nb_to_select + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_sampling\n",
    ")\n",
    "# pbgmm_sampling_without_algorithm_name <- pbnm( GLM_fit_sampling, GLM_fit_sampling_without_algorithm_name, nsim=1000, tasks=10, cores=2, seed=42 ) \n",
    "# summary(pbgmm_sampling_without_algorithm_name)\n",
    "anova_sampling_without_algorithm_name <- anova(GLM_fit_sampling, GLM_fit_sampling_without_algorithm_name, test=\"Chisq\")\n",
    "summary(anova_sampling_without_algorithm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6a229",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `dataset_size` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_fit_sampling_without_dataset_size <- glm(\n",
    "    formula = time_total ~ algorithm_name + previous_nb_constraints + previous_nb_clusters + algorithm_nb_to_select + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_sampling\n",
    ")\n",
    "# pbgmm_sampling_without_dataset_size <- pbnm( GLM_fit_sampling, GLM_fit_sampling_without_dataset_size, nsim=1000, tasks=10, cores=2, seed=42 )\n",
    "# summary(pbgmm_sampling_without_dataset_size)\n",
    "anova_sampling_without_dataset_size <- aov(GLM_fit_sampling, GLM_fit_sampling_without_dataset_size, test=\"Chisq\")\n",
    "summary(anova_sampling_without_dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac67ba3",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `previous_nb_constraints` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_fit_sampling_without_previous_nb_constraints <- glm(\n",
    "    formula = time_total ~ algorithm_name + dataset_size + previous_nb_clusters + algorithm_nb_to_select + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_sampling\n",
    ")\n",
    "# pbgmm_sampling_without_previous_nb_constraints <- pbnm( GLM_fit_sampling, GLM_fit_sampling_without_previous_nb_constraints, nsim=1000, tasks=10, cores=2, seed=42 ) \n",
    "# summary(pbgmm_sampling_without_previous_nb_constraints)\n",
    "anova_sampling_without_previous_nb_constraints <- anova(GLM_fit_sampling, GLM_fit_sampling_without_previous_nb_constraints, test=\"Chisq\")\n",
    "summary(anova_sampling_without_previous_nb_constraints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6584a",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `previous_nb_clusters` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_fit_sampling_without_previous_nb_clusters <- glm(\n",
    "    formula = time_total ~ algorithm_name + dataset_size + previous_nb_constraints + algorithm_nb_to_select + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_sampling\n",
    ")\n",
    "# pbgmm_sampling_without_previous_nb_clusters <- pbnm( GLM_fit_sampling, GLM_fit_sampling_without_previous_nb_clusters, nsim=1000, tasks=10, cores=2, seed=42 ) \n",
    "# summary(pbgmm_sampling_without_previous_nb_clusters)\n",
    "anova_sampling_without_previous_nb_clusters <- anova(GLM_fit_sampling, GLM_fit_sampling_without_previous_nb_clusters, test=\"Chisq\")\n",
    "summary(anova_sampling_without_previous_nb_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dcb67f",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data with all factors minus `algorithm_nb_to_select` and perform parametric bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df062c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLM_fit_sampling_without_algorithm_nb_to_select <- glm(\n",
    "    formula = time_total ~ algorithm_name + dataset_size + previous_nb_constraints + previous_nb_clusters + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_sampling\n",
    ")\n",
    "# pbgmm_sampling_without_algorithm_nb_to_select <- pbnm( GLM_fit_sampling, GLM_fit_sampling_without_algorithm_nb_to_select, nsim=1000, tasks=10, cores=2, seed=42 )\n",
    "# summary(pbgmm_sampling_without_algorithm_nb_to_select)\n",
    "anova_sampling_without_algorithm_nb_to_select <- anova(GLM_fit_sampling, GLM_fit_sampling_without_algorithm_nb_to_select, test=\"Chisq\")\n",
    "summary(anova_sampling_without_algorithm_nb_to_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b365dd",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57406471",
   "metadata": {},
   "source": [
    "### 2.4. ANALYSIS FOR CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f642ff1e",
   "metadata": {},
   "source": [
    "#### 2.4.1. LOAD SYNTHESIS CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b065f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analysis data.\n",
    "df_analysis_clustering <- read.csv(\n",
    "    file=\"../results/experiments_synthesis_for_clustering.csv\",\n",
    "    header=TRUE,  # Use the first row as headers.\n",
    "    sep=\";\",\n",
    "    skip=0,  # Number of rows to skip in the file.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column type.\n",
    "df_analysis_clustering$dataset_size <- as.numeric( df_analysis_clustering$dataset_size )\n",
    "df_analysis_clustering$dataset_random_seed <- as.numeric( df_analysis_clustering$dataset_random_seed )\n",
    "df_analysis_clustering$previous_nb_constraints <- as.numeric( df_analysis_clustering$previous_nb_constraints )\n",
    "df_analysis_clustering$algorithm_name <- as.factor( df_analysis_clustering$algorithm_name )\n",
    "df_analysis_clustering$algorithm_random_seed <- as.numeric( df_analysis_clustering$algorithm_random_seed )\n",
    "df_analysis_clustering$algorithm_nb_clusters <- as.numeric( df_analysis_clustering$algorithm_nb_clusters )\n",
    "df_analysis_clustering$time_total <- as.double( sub(\",\", \".\", df_analysis_clustering$time_total) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c6bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show an extract of analysis data.\n",
    "df_analysis_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619fb4bb",
   "metadata": {},
   "source": [
    "#### 2.4.2. Apply general analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2726204a",
   "metadata": {},
   "source": [
    "Fit a generalized linear model (GLM) on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c614920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GLM_fit_clustering <- glm(\n",
    "    formula = time_total ~ algorithm_name + dataset_size + previous_nb_constraints + algorithm_nb_clusters + (1 | dataset_random_seed) + (1 | algorithm_random_seed),\n",
    "    data = df_analysis_clustering\n",
    ")\n",
    "summary(GLM_fit_clustering)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
