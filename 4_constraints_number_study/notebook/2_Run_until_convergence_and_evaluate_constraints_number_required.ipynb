{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==== INTERACTIVE CLUSTERING : CONSTRAINTS NUMBER STUDY ====\n",
    "> ### Stage 2 : Run all experiments until convergence, evaluate constraints number and synthesize experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## READ-ME BEFORE RUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Description\n",
    "\n",
    "This notebook is **aimed at run all convergence experiments, evaluate interactive clustering constraints number required, and synthesize interactive clustering convergence experiments in a CSV file**.\n",
    "- Environments are represented by subdirectories in the `/experiments` folder. A full path to an experiment environment is `/experiments/[DATASET]/[PREPROCESSING]/[VECTORIZATION]/[SAMPLING]/[CLUSTERING]/[EXPERIMENT]`.\n",
    "- An experiment run is composed of iterations of _interative clustering_.\n",
    "- An experiment evaluation look at each _interative clustering_ iteration of the experiment.\n",
    "\n",
    "Before running, **run the notebook `1_Initialize_convergence_experiments.ipynb` to set up experiments you want**.\n",
    "\n",
    "Then, **go to the notebook `3_Modelize_constraints_number_and_Plot_some_figures.ipynb` to modelize constraints number and plot some figures**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description each steps\n",
    "\n",
    "First of all, find all experiment environments.\n",
    "- A loop look at all subdirectories in the `/experiments` folder that have a `config.json` file.\n",
    "\n",
    "Then, **apply experiment run** (2.A) for all experiment environments :\n",
    "- An experiment run is composed of iteration of _interative clustering_.\n",
    "    - Iterations are represented by a `string` id (the iteration number in four characters).\n",
    "- The experiment starts with data loading and constraints manager initialization.\n",
    "- Iterations are made until completness of annotation (cf. constraints manager) or until maximum iteration is reached.\n",
    "- Each iteration is composed of three major steps:\n",
    "    - a **constraints sampling step**: Based on previous clustering results, a sampler selects couples of data to annotate. On first iteration, their is no sampling.\n",
    "    - a **constraints annotation step**: Based on the groundtruth, an automatic annotator simulates the expert constraints annotation on couples of data. These annotations can be \"MUST_LINK\" or \"CANNOT_LINK\", and are based on comparison of groundtruth intents.\n",
    "    - a **constrained clustering step**: Based on constraints annotated, a clustering on data is run.\n",
    "- Note that constraints additions should correct clustering at each iteration.\n",
    "- All computations are stored in the following files:\n",
    "    - samples and annotations in `../experiments/[EXPERIMENT_PATH]/dict_of_constraints_annotations.json`;\n",
    "    - clustering results in `../experiments/[EXPERIMENT_PATH]/dict_of_clustering_results.json`;\n",
    "    - time spent in `../experiments/[EXPERIMENT_PATH]/dict_of_computation_times.json`.\n",
    "- _NB_:\n",
    "    - The script used to run an experiment is available in the `workerA_run.py` file.\n",
    "    - For these computations, **multiprocessing is used to parallelize tasks**:\n",
    "        - Each environment is represented by a task, and tasks are launched as workers on available logical CPUs.\n",
    "        - The scripts for theses workers are available in the `notebook` directory.\n",
    "        - **WARNING**: _Number of workers should reprensent the number of logical CPU reserved to avoid slow execution._\n",
    "    - Each result (annotations, computation time, clustering results) is grouped by iteration and stored in JSON files.\n",
    "\n",
    "Then, **apply experiment evaluation** (2.B) for all experiment environments:\n",
    "- Evaluate the following clustering performance metrics for each iteration: `completness`, `homogeneity`, `v-measure`, `adjusted-rand-index`, `adjusted-mutual-information`;\n",
    "- Find iterations that reach the following clustering performance goal: `v_measure=0.50`, `v_measure=0.60`, `v_measure=0.70`, `v_measure=0.80`, `v_measure=0.90`, `v_measure=0.95`, `v_measure=0.99`, `v_measure=1.00`, `annotation=completed` (others *v_measure* goals can be set if needed). This iterations are stored in `../experiments/[EXPERIMENT_PATH]/dict_of_iterations_to_highlight.json` file;\n",
    "- Plot clustering performance evolution over iterations in the `../experiments/[EXPERIMENT_PATH]/plot_clustering_performances_evolution.png` image file;\n",
    "- Plot annotation completeness evolution over iterations in the `../experiments/[EXPERIMENT_PATH]/plot_annotations_completeness_evolution.png` image file;\n",
    "- Plot compuation times evolution over iterations in the `../experiments/[EXPERIMENT_PATH]/plot_computation_times_evolution.png` image file.\n",
    "- _NB_:\n",
    "    - The script used to evaluate an experiment is available in the `workerB_evaluate.py` file.\n",
    "    - Each result (clustering evaluation) is grouped by iteration and stored in JSON files.\n",
    "\n",
    "Then, **apply experiment synthesis** (2.D) for all experiments:\n",
    "- Create a CSV file to format evaluations, annotations and time evolutions in order to analyze constraints number required according to dataset size (cf. notebook `3_Modelize_constraints_number_and_Plot_some_figures.ipynb`);\n",
    "- Evolutions are stored in the `../results/experiment_sysnthesis.csv` file.\n",
    "- _NB_:\n",
    "    - The script used to do experiments synthesis is available in the `workerD_synthesis.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## 1. IMPORT PYTHON DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing as mp\n",
    "import listing_envs\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import tqdm\n",
    "import workerA_run\n",
    "import workerB_evaluate\n",
    "import workerC_overview\n",
    "import workerD_synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## 2. RUN CONVERGENCE STUDY EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all experiment environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get list of experiment environments.\n",
    "LIST_OF_EXPERIMENT_ENVIRONMENTS: List[\n",
    "    str\n",
    "] = listing_envs.get_list_of_experiment_env_paths()\n",
    "print(\n",
    "    \"There are\",\n",
    "    \"`\" + str(len(LIST_OF_EXPERIMENT_ENVIRONMENTS)) + \"`\",\n",
    "    \"created experiment environments in `../experiments`\",\n",
    ")\n",
    "LIST_OF_EXPERIMENT_ENVIRONMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_OF_EXPERIMENT_ENVIRONMENTS = [\n",
    "    env\n",
    "    for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "    if not os.path.exists(env+\".done\")\n",
    "]\n",
    "print(\n",
    "    \"There are\",\n",
    "    \"`\" + str(len(LIST_OF_EXPERIMENT_ENVIRONMENTS)) + \"`\",\n",
    "    \"remaining experiment environments in `../experiments`\",\n",
    ")\n",
    "LIST_OF_EXPERIMENT_ENVIRONMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "### 2.A. Run all experiment defined by an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent each convergence experiment by a task to launch. Tasks define the run parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# List of run tasks to parallelize.\n",
    "list_of_convergence_tasks: List[Dict[str, Union[str, int, None]]] = [\n",
    "    {\n",
    "        \"ENV_PATH\": env_to_run,  # Environment of experiment.\n",
    "        \"MAX_ITER\": None,  # Maximum number of iteration.\n",
    "    }\n",
    "    for counter_of_run_task, env_to_run in enumerate(LIST_OF_EXPERIMENT_ENVIRONMENTS)\n",
    "]\n",
    "print(\"There are\", \"`\" + str(len(list_of_convergence_tasks)) + \"`\", \"run tasks to launch.\")\n",
    "##### list_of_run_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all defined tasks with `multiprocessing` : Each task is given to a worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of worker (logical CPU).\n",
    "number_of_workers_for_run: int = 8  # mp.cpu_count()  # TODO: set it manually !\n",
    "print(\n",
    "    \"There are\",\n",
    "    \"`\" + str(number_of_workers_for_run) + \"`\",\n",
    "    \"logical CPUs used for evaluation experiments.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tasks in parallel.\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define the pool of workers.\n",
    "    pool_for_run = mp.Pool(number_of_workers_for_run)\n",
    "\n",
    "    # Map the list of tasks with the pool of workers. Show a progress bar with `tqdm`.\n",
    "    for _ in tqdm.tqdm(  # noqa: WPS352\n",
    "        pool_for_run.imap_unordered(workerA_run.experiment_run, list_of_convergence_tasks),\n",
    "        total=len(list_of_convergence_tasks),\n",
    "    ):\n",
    "        pass  # noqa: WPS420"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "### 2.B. Evaluate all experiments defined by an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***WARNING***: _Start by launching the convergence experiments before the experiment evaluations !_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate each convergence experiment convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each environment...\n",
    "for counter_for_evaluation, exp_to_evaluate in enumerate(\n",
    "    LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "):\n",
    "\n",
    "    # Print the current experiment to evaluate.\n",
    "    print(counter_for_evaluation, \":\", exp_to_evaluate)\n",
    "    if not os.path.exists(exp_to_evaluate+\".done\"):\n",
    "        continue\n",
    "    if os.path.exists(exp_to_evaluate+\".done_evaluation\"):\n",
    "        continue\n",
    "\n",
    "    # Start the evaluation.\n",
    "    workerB_evaluate.experiment_evaluate(\n",
    "        parameters={\n",
    "            \"ENV_PATH\": exp_to_evaluate,  # Experiment of experiment.\n",
    "            \"study_progress\": \"exp: \"\n",
    "            + str(counter_for_evaluation + 1)\n",
    "            + \"/\"\n",
    "            + str(\n",
    "                len(LIST_OF_EXPERIMENT_ENVIRONMENTS)\n",
    "            ),  # Study progression.\n",
    "            \"performance_goals_to_compute\": [\n",
    "                \"0.05\",\n",
    "                \"0.10\",\n",
    "                \"0.15\",\n",
    "                \"0.20\",\n",
    "                \"0.25\",\n",
    "                \"0.30\",\n",
    "                \"0.35\",\n",
    "                \"0.40\",\n",
    "                \"0.45\",\n",
    "                \"0.50\",\n",
    "                \"0.55\",\n",
    "                \"0.60\",\n",
    "                \"0.65\",\n",
    "                \"0.70\",\n",
    "                \"0.75\",\n",
    "                \"0.80\",\n",
    "                \"0.85\",\n",
    "                \"0.90\",\n",
    "                \"0.95\",\n",
    "                \"0.99\",\n",
    "                \"1.00\",\n",
    "            ],  # Performance goal for iteration to highlight.\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "### 2.D. Synthesize experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***WARNING***: _Start by launching the experiment runs and evaluations before the experiments synthesis !_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesize performance, annotation and time in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run synthesis computation.\n",
    "workerD_synthesis.experiments_synthesis(\n",
    "    list_of_experiment_environments=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## NOTA BENE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Show the CPU usage***: `htop`\n",
    "- ***Show disk usage***: `du -sh -- *`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Zip results***: `tar -czf ../experiments.tar.gz ../experiments/`\n",
    "- ***Unzip results***: `tar -xzf ../experiments.tar.gz -C ../`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
