{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==== INTERACTIVE CLUSTERING : CONSTRAINTS NUMBER STUDY ====\n",
    "> ### Stage 2 : Run all experiments until convergence, evaluate efficience and synthesize experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## READ-ME BEFORE RUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Description\n",
    "\n",
    "This notebook is **aimed at run all convergence experiments, evaluate interactive clustering efficience over iterations, plot overviews of experiments and synthesize interactive clustering convergence experiments in a CSV file**.\n",
    "- Environments are represented by subdirectories in the `/experiments` folder. A full path to an experiment environment is `/experiments/[DATASET]/[PREPROCESSING]/[VECTORIZATION]/[SAMPLING]/[CLUSTERING]/[EXPERIMENT]`.\n",
    "- An experiment run is composed of iterations of _interative clustering_.\n",
    "- An experiment evaluation look at each _interative clustering_ iteration of the experiment.\n",
    "\n",
    "Before running, **run the notebook `1_Initialize_convergence_experiments.ipynb` to set up experiments you want**.\n",
    "\n",
    "Then, **go to the notebook `3_Analyze_main_effects_and_post_hoc.ipynb` to run main effects and and post-hoc analysis on interactive clustering constraints number over experiments**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description each steps\n",
    "\n",
    "First of all, find all experiment environments.\n",
    "- A loop look at all subdirectories in the `/experiments` folder that have a `config.json` file.\n",
    "\n",
    "Then, **apply experiment run** (2.A) for all experiment environments :\n",
    "- An experiment run is composed of iteration of _interative clustering_.\n",
    "    - Iterations are represented by a `string` id (the iteration number in four characters).\n",
    "- The experiment starts with data loading and constraints manager initialization.\n",
    "- Iterations are made until completness of annotation (cf. constraints manager) or until maximum iteration is reached.\n",
    "- Each iteration is composed of three major steps:\n",
    "    - a **constraints sampling step**: Based on previous clustering results, a sampler selects couples of data to annotate. On first iteration, their is no sampling.\n",
    "    - a **constraints annotation step**: Based on the groundtruth, an automatic annotator simulates the expert constraints annotation on couples of data. These annotations can be \"MUST_LINK\" or \"CANNOT_LINK\", and are based on comparison of groundtruth intents.\n",
    "    - a **constrained clustering step**: Based on constraints annotated, a clustering on data is run.\n",
    "- Note that constraints additions should correct clustering at each iteration.\n",
    "- All computations are stored in the following files:\n",
    "    - samples and annotations in `../experiments/[EXPERIMENT_PATH]/dict_of_constraints_annotations.json`;\n",
    "    - clustering results in `../experiments/[EXPERIMENT_PATH]/dict_of_clustering_results.json`;\n",
    "    - time spent in `../experiments/[EXPERIMENT_PATH]/dict_of_computation_times.json`.\n",
    "- _NB_:\n",
    "    - The script used to run an experiment is available in the `workerA_run.py` file.\n",
    "    - For these computations, **multiprocessing is used to parallelize tasks**:\n",
    "        - Each environment is represented by a task, and tasks are launched as workers on available logical CPUs.\n",
    "        - The scripts for theses workers are available in the `notebook` directory.\n",
    "        - **WARNING**: _Number of workers should reprensent the number of logical CPU reserved to avoid slow execution._\n",
    "    - Each result (annotations, computation time, clustering results) is grouped by iteration and stored in JSON files.\n",
    "\n",
    "Then, **apply experiment evaluation** (2.B) for all experiment environments:\n",
    "- Evaluate the following clustering performance metrics for each iteration: `completness`, `homogeneity`, `v-measure`, `adjusted-rand-index`, `adjusted-mutual-information`;\n",
    "- Find iterations that reach the following clustering performance goal: `v_measure=0.50`, `v_measure=0.60`, `v_measure=0.70`, `v_measure=0.80`, `v_measure=0.90`, `v_measure=0.95`, `v_measure=0.99`, `v_measure=1.00`, `annotation=completed` (others *v_measure* goals can be set if needed). This iterations are stored in `../experiments/[EXPERIMENT_PATH]/dict_of_iterations_to_highlight.json` file;\n",
    "- Plot clustering performance evolution over iterations in the `../experiments/[EXPERIMENT_PATH]/plot_clustering_performances_evolution.png` image file;\n",
    "- Plot annotation completeness evolution over iterations in the `../experiments/[EXPERIMENT_PATH]/plot_annotations_completeness_evolution.png` image file;\n",
    "- Plot compuation times evolution over iterations in the `../experiments/[EXPERIMENT_PATH]/plot_computation_times_evolution.png` image file.\n",
    "- _NB_:\n",
    "    - The script used to evaluate an experiment is available in the `workerB_evaluate.py` file.\n",
    "    - Each result (clustering evaluation) is grouped by iteration and stored in JSON files.\n",
    "\n",
    "Then, **apply experiment overviews** (2.C) for several sets of experiments :\n",
    "- Have an overview by computing the mean clustering performance evolution and mean clustering time evolution for a set of experiments;\n",
    "- Several overviews are computed : `all experiments`, `partial annotation (80% of v-measure)`, `sufficient annotation (100% of v-measure)` and `complete annotation (annotation completeness)`.\n",
    "- Plot global clustering performances evolution in the `../results/plot_global_performances_evolution.png` image file;\n",
    "- Plot global computation times evolution in the `../results/plot_global_computation_times_evolution.png` image file;\n",
    "- _NB_:\n",
    "    - The script used to do experiments overview is available in the `workerC_overview.py` file.\n",
    "\n",
    "Then, **apply experiment synthesis** (2.D) for all experiments:\n",
    "- Create a CSV file to format evaluations, annotations and time evolutions in order to analyze main effects and post-hoc of interactive clustering convergence speed using a `R` script (cf. notebook `3_Analyze_main_effecets_and_post_hoc.ipynb`);\n",
    "- Evolutions are stored in the `../results/experiment_sysnthesis.csv` file.\n",
    "- _NB_:\n",
    "    - The script used to do experiments synthesis is available in the `workerD_synthesis.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## 1. IMPORT PYTHON DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import listing_envs\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "import tqdm\n",
    "import workerA_run\n",
    "import workerB_evaluate\n",
    "import workerC_overview\n",
    "import workerD_synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## 2. RUN CONVERGENCE STUDY EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all experiment environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get list of experiment environments.\n",
    "LIST_OF_EXPERIMENT_ENVIRONMENTS: List[\n",
    "    str\n",
    "] = listing_envs.get_list_of_experiment_env_paths()\n",
    "print(\n",
    "    \"There are\",\n",
    "    \"`\" + str(len(LIST_OF_EXPERIMENT_ENVIRONMENTS)) + \"`\",\n",
    "    \"created experiment environments in `../experiments`\",\n",
    ")\n",
    "LIST_OF_EXPERIMENT_ENVIRONMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "### 2.A. Run all experiment defined by an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent each convergence experiment by a task to launch. Tasks define the run parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# List of run tasks to parallelize.\n",
    "list_of_convergence_tasks: List[Dict[str, Union[str, int, None]]] = [\n",
    "    {\n",
    "        \"ENV_PATH\": env_to_run,  # Environment of experiment.\n",
    "        \"MAX_ITER\": None,  # Maximum number of iteration.\n",
    "    }\n",
    "    for counter_of_run_task, env_to_run in enumerate(LIST_OF_EXPERIMENT_ENVIRONMENTS)\n",
    "]\n",
    "print(\"There are\", \"`\" + str(len(list_of_convergence_tasks)) + \"`\", \"run tasks to launch.\")\n",
    "##### list_of_run_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all defined tasks with `multiprocessing` : Each task is given to a worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of worker (logical CPU).\n",
    "number_of_workers_for_run: int = 8  # mp.cpu_count()  # TODO: set it manually !\n",
    "print(\n",
    "    \"There are\",\n",
    "    \"`\" + str(number_of_workers_for_run) + \"`\",\n",
    "    \"logical CPUs used for evaluation experiments.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tasks in parallel.\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define the pool of workers.\n",
    "    pool_for_run = mp.Pool(number_of_workers_for_run)\n",
    "\n",
    "    # Map the list of tasks with the pool of workers. Show a progress bar with `tqdm`.\n",
    "    for _ in tqdm.tqdm(  # noqa: WPS352\n",
    "        pool_for_run.imap_unordered(workerA_run.experiment_run, list_of_convergence_tasks),\n",
    "        total=len(list_of_convergence_tasks),\n",
    "    ):\n",
    "        pass  # noqa: WPS420"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "### 2.B. Evaluate all experiments defined by an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***WARNING***: _Start by launching the convergence experiments before the experiment evaluations !_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate each convergence experiment convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each environment...\n",
    "for counter_for_evaluation, exp_to_evaluate in enumerate(\n",
    "    LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "):\n",
    "\n",
    "    # Print the current experiment to evaluate.\n",
    "    print(counter_for_evaluation, \":\", exp_to_evaluate)\n",
    "\n",
    "    # Start the evaluation.\n",
    "    workerB_evaluate.experiment_evaluate(\n",
    "        parameters={\n",
    "            \"ENV_PATH\": exp_to_evaluate,  # Experiment of experiment.\n",
    "            \"study_progress\": \"exp: \"\n",
    "            + str(counter_for_evaluation + 1)\n",
    "            + \"/\"\n",
    "            + str(\n",
    "                len(LIST_OF_EXPERIMENT_ENVIRONMENTS)\n",
    "            ),  # Study progression.\n",
    "            \"performance_goals_to_compute\": [\n",
    "                \"0.05\",\n",
    "                \"0.10\",\n",
    "                \"0.15\",\n",
    "                \"0.20\",\n",
    "                \"0.25\",\n",
    "                \"0.30\",\n",
    "                \"0.35\",\n",
    "                \"0.40\",\n",
    "                \"0.45\",\n",
    "                \"0.50\",\n",
    "                \"0.55\",\n",
    "                \"0.60\",\n",
    "                \"0.65\",\n",
    "                \"0.70\",\n",
    "                \"0.75\",\n",
    "                \"0.80\",\n",
    "                \"0.85\",\n",
    "                \"0.90\",\n",
    "                \"0.95\",\n",
    "                \"0.99\",\n",
    "                \"1.00\",\n",
    "            ],  # Performance goal for iteration to highlight.\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "### 2.C. Make experiments overviews in a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***WARNING***: _Start by launching the experiment runs and evaluations before the experiments overview !_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent each convergence experiment performances overview to make."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PERFORMANCE_OVERVIEW_SETTINGS: Dict[str, Dict[str, Union[str, List[str]]]] = {\n",
    "    # Overview of all experiments.\n",
    "    \"AVERAGE\": {\n",
    "        \"title\": \"Baseline (all experiments)\",\n",
    "        \"marker\": \"\",\n",
    "        \"color\": \"0.00\",  # Grayscale, but \"black\" for colored graph.\n",
    "        \"linestyle\": \"--\",\n",
    "        \"LIST_OF_ENV_PATHS\": LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    "    },\n",
    "    # Overview of average best settings to reach 80% of v-measure (partial annotation). (cf. ANOVA analysis)\n",
    "    \"BEST_0.80v\": {\n",
    "        \"title\": \"80% of v-measure\",\n",
    "        \"marker\": \"v\",  # Downward-pointing triangle.\n",
    "        \"color\": \"0.45\",  # Grayscale, but \"orange\" for colored graph.\n",
    "        \"linestyle\": \"-\",\n",
    "        \"LIST_OF_ENV_PATHS\": [\n",
    "            env\n",
    "            for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "            if (\"simple_prep\" in env)\n",
    "            and (\"tfidf\" in env)\n",
    "            and (\"closest-50\" in env)\n",
    "            and (\"hier_avg-10c\" in env or \"hier_sing-10c\" in env)\n",
    "        ],\n",
    "    },\n",
    "    # Overview of average best settings to reach 100% of v-measure (sufficient annotation). (cf. ANOVA analysis)\n",
    "    \"BEST_1.00v\": {\n",
    "        \"title\": \"100% of v-measure\",\n",
    "        \"marker\": \"^\",  # Upward-pointing triangle.\n",
    "        \"color\": \"0.30\",  # Grayscale, but \"red\" for colored graph.\n",
    "        \"linestyle\": \"-\",\n",
    "        \"LIST_OF_ENV_PATHS\": [\n",
    "            env\n",
    "            for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "            if (\"lemma_prep\" in env)\n",
    "            and (\"tfidf\" in env)\n",
    "            and (\"closest-50\" in env)\n",
    "            and (\"kmeans_COP-10c\" in env)\n",
    "        ],\n",
    "    },\n",
    "    # Overview of average best settings to reach annotation completeness (complete annotation). (cf. ANOVA analysis)\n",
    "    \"BEST_MAX\": {\n",
    "        \"title\": \"Annotation completeness\",\n",
    "        \"marker\": \">\",  # Right-pointing triangle.\n",
    "        \"color\": \"0.15\",  # Grayscale, but \"darkred\" for colored graph.\n",
    "        \"linestyle\": \"-\",\n",
    "        \"LIST_OF_ENV_PATHS\": [\n",
    "            env\n",
    "            for env in LIST_OF_EXPERIMENT_ENVIRONMENTS\n",
    "            if (\"lemma_prep\" in env)\n",
    "            and (\"tfidf\" in env)\n",
    "            and (\"in_same-50\" in env)\n",
    "            and (\"kmeans_COP-10c\" in env)\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"There are\",\n",
    "    \"`\" + str(len(PERFORMANCE_OVERVIEW_SETTINGS.keys())) + \"`\",\n",
    "    \"performance overviews to make.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create performance overview graph with several interactive clustering convergence experiments grouped by parameters."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Run overviews computation.\n",
    "workerC_overview.experiments_performance_overview(\n",
    "    overview_settings=PERFORMANCE_OVERVIEW_SETTINGS,\n",
    "    forced_max_iter=\"0050\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent each experiments time overview to make."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TIME_OVERVIEW_SETTINGS: Dict[str, Dict[str, Union[str, List[str]]]] = {\n",
    "    # Overview of all experiments.\n",
    "    \"AVERAGE\": {\n",
    "        \"title\": \"Baseline (all experiments)\",\n",
    "        \"marker\": \"\",\n",
    "        \"color\": \"0.00\",  # Grayscale, but \"black\" for colored graph.\n",
    "        \"linestyle\": \"--\",\n",
    "        \"LIST_OF_ENV_PATHS\": LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    "    },\n",
    "    # Overview of experiments with hierarchical single-link clustering.\n",
    "    \"CLUSTERING_hier_sing\": {\n",
    "        \"title\": \"Hierarchical (single-link)\",\n",
    "        \"marker\": \"v\",\n",
    "        \"color\": \"0.45\",  # Grayscale, but a shade of blue for colored graph\n",
    "        \"linestyle\": \"-\",\n",
    "        \"LIST_OF_ENV_PATHS\": [\n",
    "            env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS if (\"hier_sing\" in env)\n",
    "        ],\n",
    "    },\n",
    "    # Overview of experiments with hierarchical complete-link clustering.\n",
    "    \"CLUSTERING_hier_comp\": {\n",
    "        \"title\": \"Hierarchical (complete-link)\",\n",
    "        \"marker\": \"^\",\n",
    "        \"color\": \"0.45\",  # Grayscale, but a shade of blue for colored graph\n",
    "        \"linestyle\": \"-\",\n",
    "        \"LIST_OF_ENV_PATHS\": [\n",
    "            env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS if (\"hier_comp\" in env)\n",
    "        ],\n",
    "    },\n",
    "    # Overview of experiments with hierarchical average-link clustering.\n",
    "    \"CLUSTERING_hier_avg\": {\n",
    "        \"title\": \"Hierarchical (average-link)\",\n",
    "        \"marker\": \">\",\n",
    "        \"color\": \"0.45\",  # Grayscale, but a shade of blue for colored graph\n",
    "        \"linestyle\": \"-\",\n",
    "        \"LIST_OF_ENV_PATHS\": [\n",
    "            env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS if (\"hier_avg\" in env)\n",
    "        ],\n",
    "    },\n",
    "    # Overview of experiments with hierarchical ward-link clustering.\n",
    "    \"CLUSTERING_hier_ward\": {\n",
    "        \"title\": \"Hierarchical (ward-link)\",\n",
    "        \"marker\": \"<\",\n",
    "        \"color\": \"0.45\",  # Grayscale, but a shade of blue for colored graph\n",
    "        \"linestyle\": \"-\",\n",
    "        \"LIST_OF_ENV_PATHS\": [\n",
    "            env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS if (\"hier_ward\" in env)\n",
    "        ],\n",
    "    },\n",
    "    # Overview of experiments with spectral clustering.\n",
    "    \"CLUSTERING_spec\": {\n",
    "        \"title\": \"Spectral (SPEC-model)\",\n",
    "        \"marker\": \"+\",\n",
    "        \"color\": \"0.30\",  # Grayscale, but a shade of blue for colored graph\n",
    "        \"linestyle\": \"-\",\n",
    "        \"LIST_OF_ENV_PATHS\": [\n",
    "            env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS if (\"spectral_SPEC\" in env)\n",
    "        ],\n",
    "    },\n",
    "    # Overview of experiments with kmeans clustering.\n",
    "    \"CLUSTERING_kmeans\": {\n",
    "        \"title\": \"KMeans (COP-model)\",\n",
    "        \"marker\": \"x\",\n",
    "        \"color\": \"0.15\",  # Grayscale, but a shade of blue for colored graph\n",
    "        \"linestyle\": \"-\",\n",
    "        \"LIST_OF_ENV_PATHS\": [\n",
    "            env for env in LIST_OF_EXPERIMENT_ENVIRONMENTS if (\"kmeans_COP\" in env)\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"There are\",\n",
    "    \"`\" + str(len(TIME_OVERVIEW_SETTINGS.keys())) + \"`\",\n",
    "    \"time overviews to make.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create time overview graph with several overviews interactive clustering convergence speed grouped by parameters."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Run overviews computation.\n",
    "workerC_overview.experiments_time_overview(\n",
    "    overview_settings=TIME_OVERVIEW_SETTINGS,\n",
    "    forced_max_iter=\"0050\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "### 2.D. Synthesize experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***WARNING***: _Start by launching the experiment runs and evaluations before the experiments synthesis !_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesize performance, annotation and time in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run synthesis computation.\n",
    "workerD_synthesis.experiments_synthesis(\n",
    "    list_of_experiment_environments=LIST_OF_EXPERIMENT_ENVIRONMENTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## NOTA BENE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Show the CPU usage***: `htop`\n",
    "- ***Show disk usage***: `du -sh -- *`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***Zip results***: `tar -czf ../experiments.tar.gz ../experiments/`\n",
    "- ***Unzip results***: `tar -xzf ../experiments.tar.gz -C ../`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
