{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27aaf1c9",
   "metadata": {},
   "source": [
    "# ==== INTERACTIVE CLUSTERING : CONSTRAINTS NUMBER STUDY ====\n",
    "> ### Stage 3 : Modelize constraints number required to converge and Plot some figures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272a43a3",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a26800",
   "metadata": {},
   "source": [
    "## READ-ME BEFORE RUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d6d2a",
   "metadata": {},
   "source": [
    "### Quick Description\n",
    "\n",
    "This notebook is **aimed at modelize constraints number required to converge and plot several figures according to previous analyses**.\n",
    "- Environments are represented by subdirectories in the `/experiments` folder. A full path to an experiment environment is `/experiments/[DATASET]/[PREPROCESSING]/[VECTORIZATION]/[SAMPLING]/[CLUSTERING]/[EXPERIMENT]`.\n",
    "- An experiment run is composed of iterations of _interative clustering_.\n",
    "- An experiment evaluation look at each _interative clustering_ iteration of the experiment.\n",
    "\n",
    "Before running, **run the notebook `2_Run_until_convergence_and_evaluate_constraints_number_required.ipynb` to run interactive clustering experiment until convergence and estimate constraints number required to converge.**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ca79c",
   "metadata": {},
   "source": [
    "### Description each steps\n",
    "\n",
    "First of all, **load experiment synthesis CSV file** that have made during interactive clustering experiments.\n",
    "1. Modelize constraints number in function of dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0ea66",
   "metadata": {},
   "source": [
    "***WARNING***: _Start by launching the experiment runs, evaluations and synthesis, and launching main effects analysis before this section !_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1cd89d",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c66064",
   "metadata": {},
   "source": [
    "## 1. IMPORT PYTHON DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c516df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy import stats as scipystats\n",
    "import statistics\n",
    "import statsmodels\n",
    "import statsmodels.api\n",
    "import statsmodels.formula.api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a668c71a",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef321a",
   "metadata": {},
   "source": [
    "## 2. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experiments: pd.DataFrame = pd.read_csv(\n",
    "    filepath_or_buffer=\"../results/experiments_synthesis.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "#df_experiments[\"V090v__constraints_total\"] = df_experiments[\"V090v__constraints_total\"].replace(\",\", \".\").astype(float)\n",
    "df_experiments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ba2a7",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1327d1a",
   "metadata": {},
   "source": [
    "## 3. ANALYZE DATA"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bf510fc",
   "metadata": {},
   "source": [
    "# Fit the model to the data and print results.\n",
    "model_by_dataset = statsmodels.formula.api.glm(\n",
    "    #formula=\"V090v__constraints_total ~ 1 + C(dataset_reference)\",\n",
    "    formula=\"V090v__constraints_total ~ 1 + dataset_size*C(dataset_reference)\",\n",
    "    data=df_experiments,\n",
    "    #formula=\"V090v__constraints_total ~ 1 + dataset_size\",\n",
    "    #data=df_experiments[df_experiments[\"dataset_reference\"]==\"bank_cards_v2\"],\n",
    "    #data=df_experiments[df_experiments[\"dataset_reference\"]==\"mlsum_fr_train_subset_v1\"],\n",
    ")\n",
    "results_by_dataset = model_by_dataset.fit()\n",
    "print(results_by_dataset.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bbed07",
   "metadata": {},
   "source": [
    "- `pvalue(dataset_reference) < 10**(-3)`\n",
    "- `bank_cards_v2            ~  52 + 2.91 * dataset_size`\n",
    "- `mlsum_fr_train_subset_v1 ~ 763 + 3.19 * dataset_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03697024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and print results.\n",
    "model_constraints_number = statsmodels.formula.api.glm(\n",
    "    formula=\"V090v__constraints_total ~ 1 + dataset_size\",\n",
    "    data=df_experiments,\n",
    ")\n",
    "results_constraints_number = model_constraints_number.fit()\n",
    "print(results_constraints_number.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869df1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the modelization.\n",
    "print(\n",
    "    \"CONSTRAINTS_NUMBER ~\",\n",
    "    \"{0:.2E}\".format(results_constraints_number.params[\"Intercept\"]),\n",
    "    \"{0:.2E}*{1}\".format(results_constraints_number.params[\"dataset_size\"], \"dataset_size\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8587252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the interpolation function.\n",
    "def interpolation_constraints_number(dataset_size) -> Tuple[float, float, float]:\n",
    "    # Initialization.\n",
    "    res_low: float = 0.0\n",
    "    res: float = 0.0\n",
    "    res_high: float = 0.0\n",
    "    # Intercept.\n",
    "    res_low += (results_constraints_number.params[\"Intercept\"] - results_constraints_number.bse[\"Intercept\"])\n",
    "    res += results_constraints_number.params[\"Intercept\"]\n",
    "    res_high += (results_constraints_number.params[\"Intercept\"] + results_constraints_number.bse[\"Intercept\"])\n",
    "    # constraints_number.\n",
    "    res_low += (results_constraints_number.params[\"dataset_size\"] - results_constraints_number.bse[\"dataset_size\"]) * dataset_size\n",
    "    res += results_constraints_number.params[\"dataset_size\"] * dataset_size\n",
    "    res_high += (results_constraints_number.params[\"dataset_size\"] + results_constraints_number.bse[\"dataset_size\"]) * dataset_size\n",
    "    # Return.\n",
    "    return res_low, res, res_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e939783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_constraints_number: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_constraints_number = fig_plot_constraints_number.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_constraints_number.set_xlim(xmin=0, xmax=5250)\n",
    "axis_plot_constraints_number.set_ylim(ymin=0, ymax=20000)\n",
    "\n",
    "# Plot constraints number (observations).\n",
    "axis_plot_constraints_number.plot(\n",
    "    df_experiments[df_experiments[\"dataset_reference\"]==\"bank_cards_v2\"][\"dataset_size\"],  # x\n",
    "    df_experiments[df_experiments[\"dataset_reference\"]==\"bank_cards_v2\"][\"V090v__constraints_total\"],  # y\n",
    "    label=\"Nombre de contraintes observé pour 'bank_cards_v2'\",\n",
    "    marker=\"x\",\n",
    "    markerfacecolor=\"red\",\n",
    "    markersize=5,\n",
    "    color=\"red\",\n",
    "    linewidth=0,\n",
    "    linestyle=\"\",\n",
    ")\n",
    "axis_plot_constraints_number.plot(\n",
    "    df_experiments[df_experiments[\"dataset_reference\"]==\"mlsum_fr_train_subset_v1\"][\"dataset_size\"],  # x\n",
    "    df_experiments[df_experiments[\"dataset_reference\"]==\"mlsum_fr_train_subset_v1\"][\"V090v__constraints_total\"],  # y\n",
    "    label=\"Nombre de contraintes observé pour 'mlsum_fr_train_subset_v1'\",\n",
    "    marker=\"+\",\n",
    "    markerfacecolor=\"blue\",\n",
    "    markersize=5,\n",
    "    color=\"blue\",\n",
    "    linewidth=0,\n",
    "    linestyle=\"\",\n",
    ")\n",
    "# Plot constraints number (modelization).\n",
    "axis_plot_constraints_number.plot(\n",
    "    range(0, 5001, 100),  # x\n",
    "    [\n",
    "        interpolation_constraints_number(x)[1]\n",
    "        for x in range(0, 5001, 100)  # x\n",
    "    ],  # y\n",
    "    label=\"Nombre de contraintes modélisé\",\n",
    "    marker=\"\",\n",
    "    markerfacecolor=\"purple\",\n",
    "    markersize=3,\n",
    "    color=\"purple\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "axis_plot_constraints_number.fill_between(\n",
    "    x=range(0, 5001, 100),  # x\n",
    "    y1=[\n",
    "        interpolation_constraints_number(x)[0]\n",
    "        for x in range(0, 5001, 100)  # x\n",
    "    ],  # y1\n",
    "    y2=[\n",
    "        interpolation_constraints_number(x)[2]\n",
    "        for x in range(0, 5001, 100)  # x\n",
    "    ],  # y2\n",
    "    color=\"purple\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_constraints_number.set_xlabel(\"nombre de données [#]\", fontsize=18,)\n",
    "axis_plot_constraints_number.set_ylabel(\"nombre de contraintes [#]\", fontsize=18,)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_constraints_number.legend(\n",
    "    loc=\"upper left\",\n",
    "    fontsize=15,\n",
    ")\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_constraints_number.grid(True)\n",
    "    \n",
    "# Store the graph.\n",
    "fig_plot_constraints_number.savefig(\n",
    "    \"../results/etude-nombre-contraintes-1-modelisation-nombre.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c38f4",
   "metadata": {},
   "source": [
    "-----\n",
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation time.\n",
    "def estimate_annotation_time(batch_size: int = 50) -> Dict[str, float]:\n",
    "    # return 202 + batch_size * 7\n",
    "    return {\n",
    "        \"min\": (95 + 6.39 * batch_size),\n",
    "        \"mean\": (202 + 6.92 * batch_size),\n",
    "        \"max\": (309 + 7.45 * batch_size),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation time.\n",
    "def estimate_computation_time(dataset_size: int) -> Dict[str, float]:\n",
    "    # return -180 + 0.211 * dataset_size\n",
    "    return {\n",
    "       \"min\": (-243 + 0.216 * dataset_size + 1.463*10**(-6) * dataset_size**2),\n",
    "       \"mean\": (-239 + 0.217 * dataset_size + 1.464*10**(-6) * dataset_size**2),\n",
    "       \"max\": (-235 + 0.218 * dataset_size + 1.465*10**(-6) * dataset_size**2),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5004446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints number.\n",
    "def estimate_constraints_number(dataset_size: int) -> Dict[str, float]:\n",
    "    # return 356 + 3.05 * dataset_size\n",
    "    return {\n",
    "        \"min\": (219 + 3.01 * dataset_size),\n",
    "        \"mean\": (356 + 3.05 * dataset_size),\n",
    "        \"max\": (492 + 3.10 * dataset_size),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7858d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total time.\n",
    "def estimate_total_time(dataset_size: int, batch_size: int) -> Dict[str, float]:\n",
    "    # Estimate constraints and iterations.\n",
    "    constraints_number: Dict[str, float] = estimate_constraints_number(dataset_size)\n",
    "    nb_iterations: Dict[str, float] = {key: (constraints_number[key]/batch_size) for key in constraints_number.keys()}\n",
    "    # Estimate annotation time.\n",
    "    time_of_one_annotation_batch: Dict[str, float] = estimate_annotation_time(batch_size)\n",
    "    total_annotation_time: Dict[str, float] = {key: (time_of_one_annotation_batch[key]*nb_iterations[key]) for key in nb_iterations.keys()}\n",
    "    # Estimate computation time.\n",
    "    time_of_one_computation_batch: Dict[str, float] = estimate_computation_time(dataset_size)\n",
    "    total_computation_time: Dict[str, float] = {key: (time_of_one_computation_batch[key]*nb_iterations[key]) for key in nb_iterations.keys()}\n",
    "    # Estimate total time.\n",
    "    total_time: Dict[str, float] = {key: (total_annotation_time[key] + total_computation_time[key]) for key in nb_iterations.keys()}\n",
    "    return {\n",
    "        \"total-min\": total_time[\"min\"],\n",
    "        \"total\": total_time[\"mean\"],\n",
    "        \"total-max\": total_time[\"max\"],\n",
    "        \"annotation-min\": total_annotation_time[\"min\"],\n",
    "        \"annotation\": total_annotation_time[\"mean\"],\n",
    "        \"annotation-max\": total_annotation_time[\"max\"],\n",
    "        \"computation-min\": total_computation_time[\"min\"],\n",
    "        \"computation\": total_computation_time[\"mean\"],\n",
    "        \"computation-max\": total_computation_time[\"max\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display total time.\n",
    "def display_total_time(dataset_size: int, batch_size: int) -> pd.DataFrame:\n",
    "    df = pd.DataFrame.from_dict(\n",
    "        data={\n",
    "            key: [value]\n",
    "            for key, value in estimate_total_time(dataset_size=dataset_size, batch_size=batch_size).items()\n",
    "        },\n",
    "        orient=\"index\",\n",
    "        columns=[\"time (seconds)\"],\n",
    "    )\n",
    "    df[\"time (minutes)\"] = df.apply(lambda row: round(row[\"time (seconds)\"] / 60, 2), axis=1)\n",
    "    df[\"time (hours)\"] = df.apply(lambda row: round(row[\"time (seconds)\"] / 60 / 60, 2), axis=1)\n",
    "    df[\"time (days)\"] = df.apply(lambda row: round(row[\"time (seconds)\"] / 60 / 60 / 24, 2), axis=1)\n",
    "    df[\"time (work days)\"] = df.apply(lambda row: round(row[\"time (seconds)\"] / 60 / 60 / 8, 2), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6941b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_size=5000, batch_size=50\n",
    "display_total_time(dataset_size=5000, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ecdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_size=5000, batch_size=100\n",
    "display_total_time(dataset_size=5000, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_size=5000, batch_size=150\n",
    "display_total_time(dataset_size=5000, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_size=5000, batch_size=200\n",
    "display_total_time(dataset_size=5000, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28d75d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a new figure.\n",
    "fig_plot_total_time: Figure = plt.figure(figsize=(15, 7.5), dpi=300)\n",
    "axis_plot_total_time = fig_plot_total_time.gca()\n",
    "\n",
    "# Set range of axis.\n",
    "axis_plot_total_time.set_xlim(xmin=0, xmax=5050)\n",
    "axis_plot_total_time.set_ylim(ymin=0, ymax=140)\n",
    "\n",
    "# Plot total time (batch 50).\n",
    "axis_plot_total_time.plot(\n",
    "    range(0, 5001, 100),  # x\n",
    "    [\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=50)[\"total\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y\n",
    "    label=\"Temps total nécessaire en annotant par paquet de   50\",\n",
    "    marker=\"\",\n",
    "    markerfacecolor=\"red\",\n",
    "    markersize=3,\n",
    "    color=\"red\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "axis_plot_total_time.fill_between(\n",
    "    x=range(0, 5001, 100),  # x\n",
    "    y1=[\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=50)[\"total-min\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y1\n",
    "    y2=[\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=50)[\"total-max\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y2\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot total time (batch 100).\n",
    "axis_plot_total_time.plot(\n",
    "    range(0, 5001, 100),  # x\n",
    "    [\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=100)[\"total\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y\n",
    "    label=\"Temps total nécessaire en annotant par paquet de 100\",\n",
    "    marker=\"\",\n",
    "    markerfacecolor=\"blue\",\n",
    "    markersize=3,\n",
    "    color=\"blue\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "axis_plot_total_time.fill_between(\n",
    "    x=range(0, 5001, 100),  # x\n",
    "    y1=[\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=100)[\"total-min\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y1\n",
    "    y2=[\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=100)[\"total-max\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y2\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot total time (batch 150).\n",
    "axis_plot_total_time.plot(\n",
    "    range(0, 5001, 100),  # x\n",
    "    [\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=150)[\"total\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y\n",
    "    label=\"Temps total nécessaire en annotant par paquet de 150\",\n",
    "    marker=\"\",\n",
    "    markerfacecolor=\"green\",\n",
    "    markersize=3,\n",
    "    color=\"green\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "axis_plot_total_time.fill_between(\n",
    "    x=range(0, 5001, 100),  # x\n",
    "    y1=[\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=150)[\"total-min\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y1\n",
    "    y2=[\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=150)[\"total-max\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y2\n",
    "    color=\"green\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Plot total time (batch 200).\n",
    "axis_plot_total_time.plot(\n",
    "    range(0, 5001, 100),  # x\n",
    "    [\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=200)[\"total\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y\n",
    "    label=\"Temps total nécessaire en annotant par paquet de 200\",\n",
    "    marker=\"\",\n",
    "    markerfacecolor=\"orange\",\n",
    "    markersize=3,\n",
    "    color=\"orange\",\n",
    "    linewidth=2,\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "axis_plot_total_time.fill_between(\n",
    "    x=range(0, 5001, 100),  # x\n",
    "    y1=[\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=200)[\"total-min\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y1\n",
    "    y2=[\n",
    "        estimate_total_time(dataset_size=dataset_size, batch_size=200)[\"total-max\"]/60/60\n",
    "        for dataset_size in range(0, 5001, 100)  # x\n",
    "    ],  # y2\n",
    "    color=\"orange\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# Set axis name.\n",
    "axis_plot_total_time.set_xlabel(\"nombre de données [#]\", fontsize=18,)\n",
    "axis_plot_total_time.set_ylabel(\"temps [heures]\", fontsize=18,)\n",
    "\n",
    "# Plot the legend.\n",
    "axis_plot_total_time.legend(\n",
    "    loc=\"upper left\",\n",
    "    fontsize=15,\n",
    ")\n",
    "\n",
    "# Plot the grid.\n",
    "axis_plot_total_time.grid(True)\n",
    "    \n",
    "# Store the graph.\n",
    "fig_plot_total_time.savefig(\n",
    "    \"../results/etude-temps-total-1-modelisation.png\",\n",
    "    dpi=300,\n",
    "    transparent=True,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
