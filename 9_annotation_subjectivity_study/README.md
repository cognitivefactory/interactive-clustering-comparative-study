# Interactive Clustering : 9. Annotation subjectivity Study

The main goal of this study is to **estimate the labeling difference impact** on clustering results.


## Hypotheses

This sub-repository provides an environment to carry out a comparative study of _Interactive Clustering_ implementation around one hypothese.
- **Robustness hypothesis**: _TODO._


## Experimental protocol

`TODO`.


## Implementation

`TODO`.


## Installation and Execution

Follow the description of `README.md` repository file in order to setup your Python/R environment.

Then follow notebooks instructions.


## Previous data

Some experiments needs data from previous studies.
Here, constraints annotations are expected from `4_constraints_number_study` study.
See the export notebook of this study and paste the exported files in the `previous` folder.


## Results

Due to the volume of data generated (around 35 GB), not all results are versioned on GitHub.

- results are zipped in a `.tar.gz` file and versioned on Zenodo : `TODO`.
- a summary of results are stored in `results`.

In order to make a save in a `.tar.gz` file, you can use the following command:
```bash
tar -czf 9_annotation_subjectivity_study.tar.gz experiments/ notebook/ previous/ results/ README.md
```


## Scientific contribution

- One section of my PhD is dedicated to this study : `TODO`.